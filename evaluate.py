#!/usr/bin/env python3
"""
è¯„ä¼°ç³»ç»Ÿ - ä½¿ç”¨ç»Ÿä¸€é…ç½®ç¡®ä¿è®­ç»ƒè¯„ä¼°é¢„æµ‹ä¸€è‡´
"""

import os
import sys
import argparse
import logging
import numpy as np
import torch
import torch.nn as nn
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
from tqdm import tqdm
from scipy.ndimage import median_filter, label, binary_closing, binary_opening, binary_dilation, binary_erosion, gaussian_filter
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥ç»Ÿä¸€é…ç½®
from unified_config import UNIFIED_CONFIG

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TopTierEvaluator:
    """é¡¶åˆŠçº§è¯„ä¼°å™¨ - é›†æˆæ‰€æœ‰å¯è§†åŒ–åŠŸèƒ½"""
    
    def __init__(self, args):
        self.args = args
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # ä½¿ç”¨ç»Ÿä¸€é…ç½®
        self.config = UNIFIED_CONFIG
        
        # è¯„ä¼°å‚æ•°ä¼˜åŒ– - å¹³è¡¡ç²¾åº¦ä¸æ•ˆç‡
        self.stride = getattr(args, 'stride', 4)  # è¯„ä¼°æ­¥é•¿
        self.window_size = getattr(args, 'window_size', 256)  # çª—å£å¤§å°
        
        # ç¡®ä¿å‚æ•°ä¸ä¸ºNone
        if self.stride is None:
            self.stride = 4
        if self.window_size is None:
            self.window_size = 256
        
        # embed_dimå‚æ•°å¤„ç†
        embed_dim = getattr(args, 'embed_dim', None)
        self.embed_dim = embed_dim if embed_dim is not None else self.config['model']['embed_dim']
        
        # ç²¾åº¦ä¼˜åŒ–å‚æ•° - ç®€åŒ–æ¨¡å¼
        self.use_multi_strategy = False  # å·²ç¦ç”¨å¤šç­–ç•¥é›†æˆï¼Œä½¿ç”¨ç®€åŒ–é¢„æµ‹
        
        # æ¶ˆèä¸“ç”¨strideï¼ˆCLIè¦†ç›–ï¼‰
        self.ablation_stride = getattr(self.args, 'ablation_stride', self.stride)
        
        # ç±»åˆ«ä¿¡æ¯
        self.class_names = [
            'Impervious surfaces', 'Building', 'Low vegetation', 
            'Tree', 'Car', 'Clutter'
        ]
        # ä¼˜åŒ–è‰²å½©é…ç½® - é«˜å¯¹æ¯”åº¦ï¼Œçªå‡ºæ­£ç¡®æ•ˆæœ
        self.colors = np.array([
            [128, 128, 128],  # Impervious - ç°è‰² (æ›´è‡ªç„¶)
            [0, 0, 255],      # Building - è“è‰² (ä¿æŒ)
            [0, 255, 0],      # Low vegetation - äº®ç»¿è‰² (æ›´çªå‡º)
            [0, 128, 0],      # Tree - æ·±ç»¿è‰² (åŒºåˆ†æ¤è¢«)
            [255, 255, 0],    # Car - é»„è‰² (é«˜å¯¹æ¯”)
            [255, 0, 255]     # Clutter - ç´«è‰² (æ›´çªå‡ºé”™è¯¯)
        ], dtype=np.uint8)
        
        # å­¦æœ¯è®ºæ–‡ä¸“ç”¨è‰²å½© (æ›´ä¸“ä¸š)
        self.academic_colors = np.array([
            [200, 200, 200],  # Impervious - æµ…ç°
            [70, 130, 180],   # Building - é’¢è“è‰²
            [50, 205, 50],    # Low vegetation - é…¸æ©™ç»¿
            [34, 139, 34],    # Tree - æ£®æ—ç»¿
            [255, 215, 0],    # Car - é‡‘è‰²
            [220, 20, 60]     # Clutter - æ·±çº¢è‰²
        ], dtype=np.uint8)
        
        # åŠ è½½æ¨¡å‹
        self._load_model()
        
        logger.info("è¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"è¯„ä¼°è®¾ç½®: embed_dim={self.embed_dim}, è¯„ä¼°stride={self.stride}, çª—å£å¤§å°={self.window_size}")
    
    def _load_model(self):
        """åŠ è½½æ¨¡å‹"""
        from acf.network import create_acf_model
        
        logger.info("åˆ›å»ºACF Networkæ¨¡å‹...")
        self.model = create_acf_model(
            dataset='vaihingen',
            num_classes=self.config['model']['num_classes'],
            embed_dim=self.config['model']['embed_dim'],
            num_heads=12,
            patch_size=16,
            num_cma_layers=3
        )
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        if os.path.exists(self.args.model_path):
            checkpoint = torch.load(self.args.model_path, map_location=self.device)
            
            # å…¼å®¹ä¸åŒçš„checkpointæ ¼å¼
            if isinstance(checkpoint, dict):
                if 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                elif 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'model' in checkpoint:
                    state_dict = checkpoint['model']
                else:
                    # å¦‚æœcheckpointæœ¬èº«å°±æ˜¯å­—å…¸ä½†æ²¡æœ‰è¿™äº›é”®ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨
                    state_dict = checkpoint
            else:
                state_dict = checkpoint
            
            # å¤„ç†DataParallelå‰ç¼€
            if any(k.startswith('module.') for k in state_dict.keys()):
                state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
            
            load_res = self.model.load_state_dict(state_dict, strict=False)
            logger.info(f"æˆåŠŸåŠ è½½æ£€æŸ¥ç‚¹: {self.args.model_path}")
            
            # æ£€æŸ¥åŠ è½½ç»“æœ
            try:
                missing = getattr(load_res, 'missing_keys', [])
                unexpected = getattr(load_res, 'unexpected_keys', [])
                if missing:
                    logger.warning(f"åŠ è½½æƒé‡ç¼ºå¤±é”®æ•°é‡: {len(missing)}ï¼Œç¤ºä¾‹: {missing[:10]}")
                if unexpected:
                    logger.warning(f"åŠ è½½æƒé‡å¤šä½™é”®æ•°é‡: {len(unexpected)}ï¼Œç¤ºä¾‹: {unexpected[:10]}")
            except Exception:
                pass
        else:
            logger.warning(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {self.args.model_path}")
        
        self.model.eval()
        self.model = self.model.to(self.device)
        
        # åˆå§‹åŒ–å¯è§†åŒ–å™¨ä¸ºNoneï¼ˆè¿™äº›æ¨¡å—ä¸å­˜åœ¨ï¼‰
        self.multimodal_feature_viz = None
        self.multimodal_viz = None
        self.multimodal_tsne_viz = None
        self.heatmap_comparison_viz = None
        self.top_tier_tsne_viz = None
        self.top_tier_heatmap_viz = None
        
        logger.info("æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def load_tiff_label(self, label_path):
        """ä½¿ç”¨OpenCVåŠ è½½TIFFæ ‡ç­¾æ–‡ä»¶"""
        try:
            label = cv2.imread(label_path, cv2.IMREAD_UNCHANGED)
            if label is None:
                logger.error(f"æ— æ³•è¯»å–æ ‡ç­¾æ–‡ä»¶: {label_path}")
                return None
            
            # å¦‚æœæ˜¯BGRæ ¼å¼çš„3é€šé“å›¾åƒï¼Œè½¬æ¢ä¸ºRGBæ ¼å¼
            if len(label.shape) == 3 and label.shape[2] == 3:
                label = cv2.cvtColor(label, cv2.COLOR_BGR2RGB)
            
            logger.info(f"æˆåŠŸè¯»å–TIFFæ ‡ç­¾æ–‡ä»¶: {label.shape}, æ•°æ®ç±»å‹: {label.dtype}")
            return label
        except Exception as e:
            logger.error(f"è¯»å–TIFFæ ‡ç­¾æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def load_vaihingen_data(self, image_id):
        """åŠ è½½Vaihingenæ•°æ®ï¼ˆä½¿ç”¨evaluate_enhanced.pyçš„æ­£ç¡®é€»è¾‘ï¼‰"""
        # RGBå›¾åƒè·¯å¾„
        rgb_path = os.path.join(self.args.data_path, 'Vaihingen', 'top', f'top_mosaic_09cm_area{image_id}.tif')
        
        # DSMå›¾åƒè·¯å¾„
        dsm_path = os.path.join(self.args.data_path, 'Vaihingen', 'DSM', f'dsm_09cm_matching_area{image_id}.tif')
        
        # æ ‡ç­¾è·¯å¾„ - ä¼˜å…ˆä½¿ç”¨gts_eroded_for_participantsï¼ˆä¸FTransUNetä¸€è‡´ï¼‰
        label_path = None
        
        # ä¼˜å…ˆçº§1: gts_eroded_for_participantsï¼ˆFTransUNetè¯„ä¼°æ ‡å‡†ï¼‰
        eroded_candidates = [
            os.path.join(self.args.data_path, 'Vaihingen', 'gts_eroded_for_participants', f'top_mosaic_09cm_area{image_id}_noBoundary.tif'),
            f'/project/lixuyang/collaborative_framework_project/data/Vaihingen/gts_eroded_for_participants/top_mosaic_09cm_area{image_id}_noBoundary.tif',
            f'/project/lixuyang/collaborative_framework_project/data/Vaihingen/ISPRS_semantic_labeing_Vaihingen_ground_truth_eroded_for_participants/top_mosaic_09cm_area{image_id}_noBoundary.tif'
        ]
        for candidate in eroded_candidates:
            if os.path.exists(candidate):
                label_path = candidate
                logger.info(f"ä½¿ç”¨erodedæ ‡ç­¾æ–‡ä»¶: {candidate}")
                break
        
        # ä¼˜å…ˆçº§2: COMPLETEç›®å½•
        if label_path is None:
            complete_candidates = [
                os.path.join(self.args.data_path, 'Vaihingen', 'ISPRS_semantic_labeling_Vaihingen_ground_truth_COMPLETE', f'top_mosaic_09cm_area{image_id}.tif'),
                f'/project/lixuyang/collaborative_framework_project/data/Vaihingen/ISPRS_semantic_labeling_Vaihingen_ground_truth_COMPLETE/top_mosaic_09cm_area{image_id}.tif'
            ]
            for candidate in complete_candidates:
                if os.path.exists(candidate):
                    label_path = candidate
                    logger.info(f"ä½¿ç”¨completeæ ‡ç­¾æ–‡ä»¶: {candidate}")
                    break
        
        # ä¼˜å…ˆçº§3: gts_for_participants
        if label_path is None:
            fallback_path = os.path.join(self.args.data_path, 'Vaihingen', 'gts_for_participants', f'top_mosaic_09cm_area{image_id}.tif')
            if os.path.exists(fallback_path):
                label_path = fallback_path
                logger.info(f"ä½¿ç”¨fallbackæ ‡ç­¾æ–‡ä»¶: {fallback_path}")
        
        if label_path is None:
            logger.error(f"æ— æ³•æ‰¾åˆ°Area {image_id}çš„æ ‡ç­¾æ–‡ä»¶")
            return None, None, None
        
        # åŠ è½½RGB
        rgb = cv2.imread(rgb_path)
        if rgb is not None:
            rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)
        else:
            logger.error(f"æ— æ³•è¯»å–RGBæ–‡ä»¶: {rgb_path}")
            return None, None, None
        
        # åŠ è½½DSM
        dsm = cv2.imread(dsm_path, cv2.IMREAD_UNCHANGED)
        if dsm is None:
            logger.error(f"æ— æ³•è¯»å–DSMæ–‡ä»¶: {dsm_path}")
            return None, None, None
        
        # åŠ è½½æ ‡ç­¾
        label = self.load_tiff_label(label_path)
        if label is None:
            return None, None, None
        
        # è½¬æ¢ä¸ºç±»åˆ«ç´¢å¼•
        if label.ndim == 3:
            from universal_dataset import UniversalMultiModalDataset
            label = UniversalMultiModalDataset.convert_from_color(label)
        
        # æ£€æŸ¥æ ‡ç­¾å€¼
        unique_before = np.unique(label)
        logger.info(f"Area {image_id} è½¬æ¢å‰æ ‡ç­¾å€¼: {unique_before}")
        
        # ç¡®ä¿æ ‡ç­¾å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†… [0, 5]
        # å¦‚æœæ ‡ç­¾å€¼ä¸åœ¨[0,5]èŒƒå›´å†…ï¼Œéœ€è¦é‡æ–°æ˜ å°„
        label = label.astype(np.int32)
        if np.any(label < 0) or np.any(label > 5):
            logger.warning(f"Area {image_id} æ£€æµ‹åˆ°æ ‡ç­¾å€¼è¶…å‡º[0,5]èŒƒå›´: min={label.min()}, max={label.max()}")
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¾¹ç•Œæ ‡ç­¾ï¼ˆåªæœ‰0å’Œ255ï¼‰
            unique_values = np.unique(label)
            if len(unique_values) == 2 and 0 in unique_values and 255 in unique_values:
                logger.error(f"Area {image_id} æ£€æµ‹åˆ°è¾¹ç•Œæ ‡ç­¾ï¼ˆåªæœ‰0å’Œ255ï¼‰ï¼Œè¿™æ˜¯ä¸æ­£ç¡®çš„6ç±»æ ‡ç­¾ï¼")
                logger.error(f"è¯·æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
                return None, None, None
            # å¦åˆ™ï¼Œå°è¯•æ˜ å°„åˆ°[0,5]
            label = np.clip(label, 0, 5)
        
        label = label.astype(np.uint8)
        
        # æ£€æŸ¥æ ‡ç­¾å€¼åˆ†å¸ƒ
        unique_labels = np.unique(label)
        label_distribution = dict(zip(*np.unique(label, return_counts=True)))
        logger.info(f"Area {image_id} æ ‡ç­¾å€¼èŒƒå›´: {unique_labels}, æ ‡ç­¾å€¼åˆ†å¸ƒ: {label_distribution}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦çš„ç±»åˆ«
        if len(unique_labels) < 2:
            logger.warning(f"Area {image_id} æ ‡ç­¾åªåŒ…å«{len(unique_labels)}ä¸ªç±»åˆ«ï¼Œå¯èƒ½æœ‰é—®é¢˜")
        
        # ç‰¹åˆ«æ£€æŸ¥æ˜¯å¦æœ‰ç±»åˆ«5ï¼ˆClutterï¼‰
        if 5 not in unique_labels:
            logger.warning(f"Area {image_id} æ ‡ç­¾ä¸­æ²¡æœ‰ç±»åˆ«5ï¼ˆClutterï¼‰")
        
        return rgb, dsm, label
    
    def predict_basic(self, rgb, dsm):
        """åŸºç¡€é¢„æµ‹ç³»ç»Ÿ - ç®€åŒ–é«˜æ•ˆ"""
        h, w = rgb.shape[:2]
        num_classes = 6
        
        # ç´¯ç§¯logits
        prediction_logits = np.zeros((h, w, num_classes), dtype=np.float32)
        count_map = np.zeros((h, w), dtype=np.float32)
        
        # DSMå½’ä¸€åŒ–
        dsm_min, dsm_max = float(dsm.min()), float(dsm.max())
        dsm_norm = (dsm - dsm_min) / (dsm_max - dsm_min + 1e-8)
        
        # æ»‘åŠ¨çª—å£é¢„æµ‹ - å¿«é€Ÿæ¨¡å¼ + è¿›åº¦æ˜¾ç¤º
        y_max = max(1, h - self.window_size + 1) if h > self.window_size else 1
        x_max = max(1, w - self.window_size + 1) if w > self.window_size else 1
        
        total_windows = ((y_max - 1) // self.stride + 1) * ((x_max - 1) // self.stride + 1)
        processed_windows = 0
        progress_interval = max(1, total_windows // 10)  # æ¯10%æ˜¾ç¤ºä¸€æ¬¡
        
        logger.info(f"ğŸš€ å¿«é€Ÿé¢„æµ‹ä¸­... ({total_windows} çª—å£, {h}x{w}, stride={self.stride})")
        
        for y in range(0, y_max, self.stride):
            for x in range(0, x_max, self.stride):
                processed_windows += 1
                
                # æ¯10%æ˜¾ç¤ºè¿›åº¦
                if processed_windows % progress_interval == 0 or processed_windows == total_windows:
                    progress = (processed_windows / total_windows) * 100
                    logger.info(f"  âš¡ é¢„æµ‹è¿›åº¦: {progress:.0f}% ({processed_windows}/{total_windows})")
                
                # æå–çª—å£
                rgb_window = rgb[y:y+self.window_size, x:x+self.window_size]
                dsm_window = dsm_norm[y:y+self.window_size, x:x+self.window_size]
                
                # è½¬æ¢ä¸ºtensor
                rgb_tensor = torch.from_numpy(rgb_window.astype(np.float32) / 255.0).permute(2, 0, 1).unsqueeze(0).to(self.device)
                dsm_tensor = torch.from_numpy(dsm_window.astype(np.float32)).unsqueeze(0).unsqueeze(0).to(self.device)
                
                # åŸºç¡€é¢„æµ‹ï¼ˆæ— å¢å¼ºï¼‰
                with torch.no_grad():
                    output = self.model({'rgb': rgb_tensor, 'dsm': dsm_tensor})
                    if isinstance(output, tuple):
                        output = output[0]
                    
                    logits_np = output.cpu().numpy()[0].transpose(1, 2, 0)
                    
                    # ç´¯ç§¯ç»“æœ
                    prediction_logits[y:y+self.window_size, x:x+self.window_size] += logits_np
                    count_map[y:y+self.window_size, x:x+self.window_size] += 1
        
        # å¹³å‡åŒ–é‡å åŒºåŸŸ
        count_map[count_map == 0] = 1
        prediction_logits = prediction_logits / count_map[..., np.newaxis]
        
        # è·å–æœ€ç»ˆé¢„æµ‹
        prediction = np.argmax(prediction_logits, axis=2).astype(np.uint8)
        confidence_map = np.max(prediction_logits, axis=2)
        
        return prediction, prediction_logits, confidence_map
    
    def predict_with_intermediate_features(self, rgb, dsm):
        """é¢„æµ‹å¹¶è¿”å›ä¸­é—´ç‰¹å¾"""
        h, w = rgb.shape[:2]
        num_classes = 6
        
        # ç´¯ç§¯logits
        prediction_logits = np.zeros((h, w, num_classes), dtype=np.float32)
        count_map = np.zeros((h, w), dtype=np.float32)
        confidence_map = np.zeros((h, w), dtype=np.float32)
        
        # å­˜å‚¨ä¸­é—´ç‰¹å¾ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        intermediate_features_list = []
        
        # DSMå½’ä¸€åŒ–ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        dsm_min, dsm_max = float(dsm.min()), float(dsm.max())
        dsm_norm = (dsm - dsm_min) / (dsm_max - dsm_min + 1e-8)
        
        # æ»‘åŠ¨çª—å£é¢„æµ‹
        logger.info(f"å¼€å§‹æ»‘åŠ¨çª—å£é¢„æµ‹ï¼Œå›¾åƒå°ºå¯¸: {h}x{w}, çª—å£å¤§å°: {self.window_size}, æ­¥é•¿: {self.stride}")
        for y in tqdm(range(0, h - self.window_size + 1, self.stride), desc='é¢„æµ‹ä¸­'):
            for x in range(0, w - self.window_size + 1, self.stride):
                rgb_window = rgb[y:y+self.window_size, x:x+self.window_size]
                dsm_window = dsm_norm[y:y+self.window_size, x:x+self.window_size]
                
                # é¢„å¤„ç†ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
                rgb_tensor = torch.from_numpy(rgb_window).permute(2, 0, 1).float().unsqueeze(0) / 255.0
                dsm_tensor = torch.from_numpy(dsm_window).unsqueeze(0).unsqueeze(0).float()
                
                rgb_tensor = rgb_tensor.to(self.device)
                dsm_tensor = dsm_tensor.to(self.device)
                
                # é¢„æµ‹ï¼ˆè¿”å›ä¸­é—´ç‰¹å¾ï¼‰
                with torch.no_grad():
                    result = self.model({'rgb': rgb_tensor, 'dsm': dsm_tensor})
                    if isinstance(result, tuple):
                        output, intermediate_features = result
                    else:
                        output = result
                        intermediate_features = {}
                    # è®¡ç®—patchç½®ä¿¡åº¦
                    patch_probs = torch.softmax(output, dim=1)
                    patch_conf = torch.max(patch_probs, dim=1)[0]  # (1, H, W)
                
                # ç´¯ç§¯logitsï¼ˆä½¿ç”¨åŸå§‹logitsï¼Œè€Œä¸æ˜¯softmaxæ¦‚ç‡ï¼‰
                logits_np = output.cpu().numpy()[0].transpose(1, 2, 0)
                prediction_logits[y:y+self.window_size, x:x+self.window_size, :logits_np.shape[2]] += logits_np
                conf_np = patch_conf.detach().cpu().numpy()[0]
                confidence_map[y:y+self.window_size, x:x+self.window_size] += conf_np
                count_map[y:y+self.window_size, x:x+self.window_size] += 1
                
                # ä¿å­˜ä¸­é—´ç‰¹å¾ï¼ˆåªä¿å­˜ç¬¬ä¸€ä¸ªçª—å£ï¼Œé¿å…å†…å­˜è¿‡å¤§ï¼‰
                if len(intermediate_features_list) == 0:
                    intermediate_features_list.append(intermediate_features)
                
                del rgb_tensor, dsm_tensor, output, intermediate_features
                torch.cuda.empty_cache()
        
        # å¤„ç†è¾¹ç•Œæƒ…å†µï¼šè¡¥é½æœ€åº•è¡Œã€æœ€å³åˆ—ã€å³ä¸‹è§’
        if (h - self.window_size) % self.stride != 0:
            y = h - self.window_size
            for x in range(0, w - self.window_size + 1, self.stride):
                rgb_window = rgb[y:y+self.window_size, x:x+self.window_size]
                dsm_window = dsm_norm[y:y+self.window_size, x:x+self.window_size]
                rgb_tensor = torch.from_numpy(rgb_window).permute(2, 0, 1).float().unsqueeze(0) / 255.0
                dsm_tensor = torch.from_numpy(dsm_window).unsqueeze(0).unsqueeze(0).float()
                rgb_tensor = rgb_tensor.to(self.device)
                dsm_tensor = dsm_tensor.to(self.device)
                with torch.no_grad():
                    result = self.model({'rgb': rgb_tensor, 'dsm': dsm_tensor})
                    output = result[0] if isinstance(result, tuple) else result
                    patch_probs = torch.softmax(output, dim=1)
                    patch_conf = torch.max(patch_probs, dim=1)[0]
                logits_np = output.cpu().numpy()[0].transpose(1, 2, 0)
                prediction_logits[y:y+self.window_size, x:x+self.window_size, :logits_np.shape[2]] += logits_np
                confidence_map[y:y+self.window_size, x:x+self.window_size] += patch_conf.detach().cpu().numpy()[0]
                count_map[y:y+self.window_size, x:x+self.window_size] += 1
                del rgb_tensor, dsm_tensor, output, patch_probs, patch_conf
                torch.cuda.empty_cache()
        if (w - self.window_size) % self.stride != 0:
            x = w - self.window_size
            for y in range(0, h - self.window_size + 1, self.stride):
                rgb_window = rgb[y:y+self.window_size, x:x+self.window_size]
                dsm_window = dsm_norm[y:y+self.window_size, x:x+self.window_size]
                rgb_tensor = torch.from_numpy(rgb_window).permute(2, 0, 1).float().unsqueeze(0) / 255.0
                dsm_tensor = torch.from_numpy(dsm_window).unsqueeze(0).unsqueeze(0).float()
                rgb_tensor = rgb_tensor.to(self.device)
                dsm_tensor = dsm_tensor.to(self.device)
                with torch.no_grad():
                    result = self.model({'rgb': rgb_tensor, 'dsm': dsm_tensor})
                    output = result[0] if isinstance(result, tuple) else result
                    patch_probs = torch.softmax(output, dim=1)
                    patch_conf = torch.max(patch_probs, dim=1)[0]
                logits_np = output.cpu().numpy()[0].transpose(1, 2, 0)
                prediction_logits[y:y+self.window_size, x:x+self.window_size, :logits_np.shape[2]] += logits_np
                confidence_map[y:y+self.window_size, x:x+self.window_size] += patch_conf.detach().cpu().numpy()[0]
                count_map[y:y+self.window_size, x:x+self.window_size] += 1
                del rgb_tensor, dsm_tensor, output, patch_probs, patch_conf
                torch.cuda.empty_cache()
        if (h - self.window_size) % self.stride != 0 and (w - self.window_size) % self.stride != 0:
            y, x = h - self.window_size, w - self.window_size
            rgb_window = rgb[y:y+self.window_size, x:x+self.window_size]
            dsm_window = dsm_norm[y:y+self.window_size, x:x+self.window_size]
            rgb_tensor = torch.from_numpy(rgb_window).permute(2, 0, 1).float().unsqueeze(0) / 255.0
            dsm_tensor = torch.from_numpy(dsm_window).unsqueeze(0).unsqueeze(0).float()
            rgb_tensor = rgb_tensor.to(self.device)
            dsm_tensor = dsm_tensor.to(self.device)
            with torch.no_grad():
                result = self.model({'rgb': rgb_tensor, 'dsm': dsm_tensor})
                output = result[0] if isinstance(result, tuple) else result
                patch_probs = torch.softmax(output, dim=1)
                patch_conf = torch.max(patch_probs, dim=1)[0]
            logits_np = output.cpu().numpy()[0].transpose(1, 2, 0)
            prediction_logits[y:y+self.window_size, x:x+self.window_size, :logits_np.shape[2]] += logits_np
            confidence_map[y:y+self.window_size, x:x+self.window_size] += patch_conf.detach().cpu().numpy()[0]
            count_map[y:y+self.window_size, x:x+self.window_size] += 1
            del rgb_tensor, dsm_tensor, output, patch_probs, patch_conf
            torch.cuda.empty_cache()

        # å¹³å‡logitsä¸ç½®ä¿¡åº¦
        count_map[count_map == 0] = 1
        prediction_logits /= count_map[:, :, np.newaxis]
        confidence_map /= count_map
        
        # argmaxå¾—åˆ°é¢„æµ‹
        prediction = np.argmax(prediction_logits, axis=2).astype(np.uint8)
        
        # è¯Šæ–­ï¼šæ£€æŸ¥é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ
        unique_pred_classes = np.unique(prediction)
        logger.info(f"é¢„æµ‹ç±»åˆ«åˆ†å¸ƒï¼ˆargmaxåï¼‰: {unique_pred_classes}")
        logger.info(f"å„ç±»åˆ«é¢„æµ‹åƒç´ æ•°: {dict(zip(*np.unique(prediction, return_counts=True)))}")
        
        # è¯Šæ–­ï¼šæ£€æŸ¥logitsçš„åˆ†å¸ƒ
        logits_mean = np.mean(prediction_logits, axis=(0, 1))
        logits_std = np.std(prediction_logits, axis=(0, 1))
        logger.info(f"Logitså‡å€¼: {logits_mean}")
        logger.info(f"Logitsæ ‡å‡†å·®: {logits_std}")
        
        return prediction, prediction_logits, confidence_map, (intermediate_features_list[0] if intermediate_features_list else {})
    
    def enhanced_postprocess(self, prediction, confidence_map=None, min_area=100):
        """
        å¢å¼ºåå¤„ç† - æè‡´å‡å°‘è¯¯åˆ†é”™åˆ†ï¼ˆå¤šæ­¥éª¤ç²¾ç»†åŒ–å¤„ç†ï¼‰
        ç›®æ ‡ï¼šé¢„æµ‹å›¾ä¸GTé«˜åº¦ä¸€è‡´ï¼Œé”™åˆ†è¯¯åˆ†<3%
        """
        prediction_smooth = prediction.copy().astype(np.int32)
        
        # æ­¥éª¤1: åŸºäºç½®ä¿¡åº¦çš„åˆæ­¥ä¿®æ­£ï¼ˆä¼˜å…ˆå¤„ç†ä½ç½®ä¿¡åº¦åŒºåŸŸï¼Œæ›´ä¸¥æ ¼ï¼‰
        if confidence_map is not None:
            # ä»é…ç½®è¯»å–ç½®ä¿¡åº¦é˜ˆå€¼
            try:
                from unified_config import EVAL_CONFIG
                confidence_threshold = EVAL_CONFIG['postprocess'].get('confidence_threshold', 0.55)
            except:
                confidence_threshold = 0.55
            
            # å¯¹ä½ç½®ä¿¡åº¦åŒºåŸŸï¼ˆ<thresholdï¼‰ï¼Œä½¿ç”¨å‘¨å›´é«˜ç½®ä¿¡åº¦åŒºåŸŸçš„ç±»åˆ«
            low_confidence_mask = confidence_map < confidence_threshold
            if np.any(low_confidence_mask):
                # ä½¿ç”¨æ›´å¤§çš„æ»¤æ³¢æ ¸ï¼Œæ›´å¹³æ»‘ï¼ˆ7â†’9ï¼‰
                prediction_filtered = median_filter(prediction_smooth.astype(np.float32), size=9).astype(np.int32)
                prediction_smooth[low_confidence_mask] = prediction_filtered[low_confidence_mask]
        
        # æ­¥éª¤2: ç§»é™¤å°è¿é€šåŸŸï¼ˆæ›´ä¸¥æ ¼çš„é˜ˆå€¼ï¼‰
        for cls_id in range(6):
            mask = (prediction_smooth == cls_id).astype(np.uint8)
            if np.sum(mask) == 0:
                continue
            
            labeled_mask, num_features = label(mask)
            
            for label_id in range(1, num_features + 1):
                component_mask = (labeled_mask == label_id)
                component_size = np.sum(component_mask)
                
                if component_size < min_area:
                    # æ‰©å±•æœç´¢èŒƒå›´ï¼Œæ‰¾åˆ°å‘¨å›´ä¸»è¦ç±»åˆ«
                    y_coords, x_coords = np.where(component_mask)
                    y_min = max(0, y_coords.min() - 5)
                    y_max = min(prediction_smooth.shape[0], y_coords.max() + 6)
                    x_min = max(0, x_coords.min() - 5)
                    x_max = min(prediction_smooth.shape[1], x_coords.max() + 6)
                    
                    neighbor_region = prediction_smooth[y_min:y_max, x_min:x_max].copy()
                    component_mask_cropped = component_mask[y_min:y_max, x_min:x_max]
                    neighbor_values = neighbor_region[~component_mask_cropped]
                    
                    if len(neighbor_values) > 0:
                        # ä½¿ç”¨åŠ æƒæŠ•ç¥¨ï¼Œæ›´å€¾å‘äºä¸»è¦ç±»åˆ«
                        counts = np.bincount(neighbor_values[neighbor_values >= 0], minlength=6)
                        most_common = np.argmax(counts)
                        prediction_smooth[component_mask] = most_common
        
        # æ­¥éª¤3: å½¢æ€å­¦æ“ä½œå¹³æ»‘è¾¹ç•Œï¼ˆå¤šè½®å¤„ç†ï¼Œæ›´å¼ºï¼‰
        # ä»é…ç½®è¯»å–å½¢æ€å­¦å‚æ•°
        try:
            from unified_config import EVAL_CONFIG
            closing_size = EVAL_CONFIG['postprocess']['morphology'].get('closing_size', 7)
            opening_size = EVAL_CONFIG['postprocess']['morphology'].get('opening_size', 5)
        except:
            closing_size = 7
            opening_size = 5
        
        for cls_id in range(6):
            mask = (prediction_smooth == cls_id).astype(bool)
            if np.sum(mask) == 0:
                continue
            
            # ç¬¬ä¸€è½®ï¼šé—­è¿ç®—å¡«å……å°æ´ï¼ˆä½¿ç”¨é…ç½®çš„å¤§å°ï¼‰
            mask_closed = binary_closing(mask, structure=np.ones((closing_size, closing_size)))
            # ç¬¬äºŒè½®ï¼šå¼€è¿ç®—å»é™¤å°çªèµ·ï¼ˆä½¿ç”¨é…ç½®çš„å¤§å°ï¼‰
            mask_opened = binary_opening(mask_closed, structure=np.ones((opening_size, opening_size)))
            # ç¬¬ä¸‰è½®ï¼šè½»å¾®è†¨èƒ€å¹³æ»‘è¾¹ç•Œï¼ˆå¢å¼ºï¼‰
            mask_smooth = binary_dilation(mask_opened, structure=np.ones((3, 3)))
            mask_smooth = binary_erosion(mask_smooth, structure=np.ones((3, 3)))
            
            prediction_smooth[mask_smooth & ~mask] = cls_id
        
        # æ­¥éª¤4: åŸºäºç©ºé—´ä¸€è‡´æ€§çš„ä¿®æ­£ï¼ˆä½¿ç”¨CRF-likeå¹³æ»‘ï¼Œæ›´å¼ºï¼‰
        # ä»é…ç½®è¯»å–CRFå‚æ•°
        try:
            from unified_config import EVAL_CONFIG
            use_crf = EVAL_CONFIG['postprocess'].get('use_crf_smoothing', True)
            crf_sigma = EVAL_CONFIG['postprocess'].get('crf_sigma', 1.5)
        except:
            use_crf = True
            crf_sigma = 1.5
        
        if use_crf:
            for cls_id in range(6):
                mask = (prediction_smooth == cls_id).astype(float)
                # é«˜æ–¯å¹³æ»‘ï¼ˆä½¿ç”¨é…ç½®çš„sigmaï¼‰
                mask_smooth = gaussian_filter(mask, sigma=crf_sigma)
                # å¯¹äºè¾¹ç•ŒåŒºåŸŸï¼ˆ0.3 < mask_smooth < 0.7ï¼‰ï¼Œä½¿ç”¨å‘¨å›´ä¸»è¦ç±»åˆ«
                boundary_mask = (mask_smooth > 0.3) & (mask_smooth < 0.7) & (mask == 0)
                if np.any(boundary_mask):
                    # ä½¿ç”¨æ›´å¤§çš„ä¸­å€¼æ»¤æ³¢æ ¸ç¡®å®šè¾¹ç•ŒåŒºåŸŸçš„ç±»åˆ«ï¼ˆ5â†’7ï¼‰
                    prediction_float = prediction_smooth.astype(float)
                    prediction_smooth_boundary = median_filter(prediction_float, size=7)
                    prediction_smooth[boundary_mask] = np.round(prediction_smooth_boundary[boundary_mask]).astype(int)
        
        # æ­¥éª¤5: æœ€ç»ˆæ¸…ç†å’ŒéªŒè¯
        prediction_smooth = np.clip(prediction_smooth, 0, 5)
        
        # ç§»é™¤å­¤ç«‹ç‚¹ï¼ˆå•åƒç´ è¯¯åˆ†ï¼‰
        for cls_id in range(6):
            mask = (prediction_smooth == cls_id).astype(np.uint8)
            if np.sum(mask) == 0:
                continue
            labeled_mask, num_features = label(mask)
            for label_id in range(1, num_features + 1):
                component_mask = (labeled_mask == label_id)
                if np.sum(component_mask) == 1:  # å•åƒç´ 
                    y, x = np.where(component_mask)
                    # ä½¿ç”¨3x3é‚»åŸŸçš„ä¸»è¦ç±»åˆ«
                    y_min = max(0, y[0] - 1)
                    y_max = min(prediction_smooth.shape[0], y[0] + 2)
                    x_min = max(0, x[0] - 1)
                    x_max = min(prediction_smooth.shape[1], x[0] + 2)
                    neighbor_values = prediction_smooth[y_min:y_max, x_min:x_max].flatten()
                    neighbor_values = neighbor_values[neighbor_values != cls_id]
                    if len(neighbor_values) > 0:
                        prediction_smooth[component_mask] = np.bincount(neighbor_values).argmax()
        
        return prediction_smooth.astype(np.uint8)
    
    def evaluate_area(self, area_id):
        """è¯„ä¼°å•ä¸ªåŒºåŸŸå¹¶ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–"""
        import time
        area_start_time = time.time()
        
        logger.info(f"ğŸ¯ å¿«é€Ÿè¯„ä¼°Area {area_id}...")
        
        # åŠ è½½æ•°æ®
        rgb, dsm, label = self.load_vaihingen_data(area_id)
        if rgb is None or dsm is None or label is None:
            logger.error(f"âŒ æ— æ³•åŠ è½½Area {area_id}æ•°æ®")
            return None
        
        # å¿«é€Ÿé¢„æµ‹
        prediction, logits, confidence_map = self.predict_basic(rgb, dsm)
        
        # è·å–ä¸­é—´ç‰¹å¾ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        _, _, _, intermediate_features = self.predict_with_intermediate_features(rgb, dsm)
        
        # ç¡®ä¿é¢„æµ‹å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†… [0, 5]
        prediction = np.clip(prediction, 0, 5).astype(np.uint8)
        
        # è¯Šæ–­ï¼šæ£€æŸ¥é¢„æµ‹å’Œæ ‡ç­¾çš„ç±»åˆ«åˆ†å¸ƒ
        unique_pred = np.unique(prediction)
        unique_label = np.unique(label)
        logger.info(f"Area {area_id} - é¢„æµ‹å‰è¯Šæ–­:")
        logger.info(f"  é¢„æµ‹ç±»åˆ«: {unique_pred}, æ ‡ç­¾ç±»åˆ«: {unique_label}")
        logger.info(f"  é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ: {dict(zip(*np.unique(prediction, return_counts=True)))}")
        logger.info(f"  æ ‡ç­¾ç±»åˆ«åˆ†å¸ƒ: {dict(zip(*np.unique(label, return_counts=True)))}")
        
        # æ£€æŸ¥ï¼šå¦‚æœé¢„æµ‹ä¸­æ²¡æœ‰æŸäº›æ ‡ç­¾ä¸­çš„ç±»åˆ«ï¼Œè®°å½•è­¦å‘Š
        missing_in_pred = set(unique_label) - set(unique_pred)
        extra_in_pred = set(unique_pred) - set(unique_label)
        if missing_in_pred:
            logger.warning(f"Area {area_id} - é¢„æµ‹ä¸­ç¼ºå°‘æ ‡ç­¾ä¸­çš„ç±»åˆ«: {missing_in_pred}")
        if extra_in_pred:
            logger.warning(f"Area {area_id} - é¢„æµ‹ä¸­æœ‰æ ‡ç­¾ä¸­æ²¡æœ‰çš„ç±»åˆ«: {extra_in_pred}")
        
        # ç½®ä¿¡åº¦å›¾å·²åœ¨æ»‘çª—é˜¶æ®µæŒ‰patchå¹³å‡å¾—åˆ°
        
        # åå¤„ç†ï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨æè‡´åå¤„ç†ï¼Œç¡®ä¿é¢„æµ‹å›¾ä¸GTé«˜åº¦ä¸€è‡´ï¼‰
        # ä»é…ç½®è¯»å–min_area
        try:
            from unified_config import EVAL_CONFIG
            min_area = EVAL_CONFIG['postprocess'].get('min_area', 100)
        except:
            min_area = 100
        prediction = self.enhanced_postprocess(prediction, confidence_map, min_area=min_area)
        
        # åå¤„ç†åå†ç¡®ä¿èŒƒå›´
        prediction = np.clip(prediction, 0, 5).astype(np.uint8)
        
        # ç®€åŒ–çš„Clutterå¢å¼ºå¤„ç†ï¼ˆé¿å…å†…å­˜é—®é¢˜ï¼‰
        if self.clutter_enhancer is not None:
            logger.info(f"Area {area_id} - åº”ç”¨è½»é‡çº§Clutterå¢å¼º...")
            original_prediction = prediction.copy()
            
            try:
                # åº”ç”¨Clutterå¢å¼ºï¼ˆåªä¼ é€’å¿…è¦å‚æ•°ï¼‰
                prediction = self.clutter_enhancer.enhance_clutter_prediction(
                    prediction=prediction,
                    rgb_image=rgb,
                    confidence_map=confidence_map
                    # ä¸ä¼ é€’featuresï¼Œå‡å°‘å†…å­˜ä½¿ç”¨
                )
                
                # ç®€å•ç»Ÿè®¡
                original_clutter = np.sum(original_prediction == 5)
                enhanced_clutter = np.sum(prediction == 5)
                
                logger.info(f"Area {area_id} - Clutterå¢å¼ºæ•ˆæœ:")
                logger.info(f"  åŸå§‹Clutteråƒç´ : {original_clutter}")
                logger.info(f"  å¢å¼ºåClutteråƒç´ : {enhanced_clutter}")
                logger.info(f"  åƒç´ å¢åŠ : {enhanced_clutter - original_clutter}")
                
            except Exception as e:
                logger.error(f"Clutterå¢å¼ºå¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹é¢„æµ‹")
                prediction = original_prediction
        
        # åå¤„ç†åè¯Šæ–­
        unique_pred_after = np.unique(prediction)
        logger.info(f"Area {area_id} - æœ€ç»ˆé¢„æµ‹ç±»åˆ«: {unique_pred_after}")
        logger.info(f"Area {area_id} - åå¤„ç†åé¢„æµ‹ç±»åˆ«åˆ†å¸ƒ: {dict(zip(*np.unique(prediction, return_counts=True)))}")
        
        # ç¡®ä¿æ ‡ç­¾å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†… [0, 5]
        label = np.clip(label, 0, 5).astype(np.uint8)
        
        # è®¡ç®—æŒ‡æ ‡
        y_true = label.flatten()
        y_pred = prediction.flatten()
        
        # è£å‰ªåˆ°æœ‰æ•ˆèŒƒå›´
        valid_mask = (y_true >= 0) & (y_true < 6)
        y_true = y_true[valid_mask]
        y_pred = y_pred[valid_mask]
        
        # è®¡ç®—æ··æ·†çŸ©é˜µå’ŒæŒ‡æ ‡ï¼ˆå›ºå®š6ç±»ï¼Œç¡®ä¿æ‰€æœ‰ç±»åˆ«éƒ½è¢«è¯„ä¼°ï¼‰
        cm = confusion_matrix(y_true, y_pred, labels=np.arange(6))
        
        # æ‰“å°æ··æ·†çŸ©é˜µ
        logger.info(f"\n{'='*80}")
        logger.info(f"Area {area_id} æ··æ·†çŸ©é˜µ (6x6):")
        logger.info(f"è¡Œ=çœŸå®æ ‡ç­¾, åˆ—=é¢„æµ‹æ ‡ç­¾")
        logger.info(f"\n{cm}")
        logger.info(f"{'='*80}")
        
        # è¯¦ç»†åˆ†ææ··æ·†çŸ©é˜µ
        logger.info(f"\nArea {area_id} æ··æ·†çŸ©é˜µè¯¦ç»†åˆ†æ:")
        logger.info("è¡Œï¼ˆçœŸå®æ ‡ç­¾ï¼‰ -> åˆ—ï¼ˆé¢„æµ‹æ ‡ç­¾ï¼‰")
        for i in range(6):
            row_sum = np.sum(cm[i, :])
            col_sum = np.sum(cm[:, i])
            logger.info(f"\nç±»åˆ« {i} ({self.class_names[i]}):")
            logger.info(f"  çœŸå®æ ·æœ¬æ€»æ•°: {row_sum}")
            logger.info(f"  é¢„æµ‹æ ·æœ¬æ€»æ•°: {col_sum}")
            if row_sum > 0:
                pred_distribution = {self.class_names[j]: int(cm[i, j]) for j in range(6)}
                logger.info(f"  çœŸå®ç±»åˆ«{i}è¢«é¢„æµ‹ä¸ºå„ç±»åˆ«çš„æ•°é‡: {pred_distribution}")
            else:
                logger.warning(f"  âš ï¸ è­¦å‘Šï¼šæ ‡ç­¾ä¸­æ²¡æœ‰ç±»åˆ« {i} ({self.class_names[i]})")
        
        # è®¡ç®—å„ç±»åˆ«æŒ‡æ ‡ï¼ˆæ‰€æœ‰6ç±»ï¼‰
        metrics = {}
        metrics['precision'] = []
        metrics['recall'] = []
        metrics['f1'] = []
        metrics['iou'] = []
        
        logger.info(f"\n{'='*80}")
        logger.info(f"Area {area_id} å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡:")
        logger.info(f"{'='*80}")
        
        for i in range(6):
            tp = cm[i, i]
            fp = np.sum(cm[:, i]) - tp
            fn = np.sum(cm[i, :]) - tp
            
            precision = tp / (tp + fp + 1e-8)
            recall = tp / (tp + fn + 1e-8)
            f1 = 2 * precision * recall / (precision + recall + 1e-8)
            iou = tp / (tp + fp + fn + 1e-8)
            
            metrics['precision'].append(precision)
            metrics['recall'].append(recall)
            metrics['f1'].append(f1)
            metrics['iou'].append(iou)
            
            # è¯¦ç»†è¾“å‡º
            status = "âœ…" if iou > 0.1 else "âŒ"
            logger.info(f"{status} ç±»åˆ« {i} ({self.class_names[i]}): TP={tp}, FP={fp}, FN={fn}, "
                       f"Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}, IoU={iou:.4f}")
        
        # æ€»ä½“æŒ‡æ ‡
        oa = np.sum(np.diag(cm)) / np.sum(cm)
        # AA (Average Accuracy) = å„ç±»åˆ«Recallçš„å¹³å‡å€¼ï¼ˆä¸æ˜¯Precisionï¼‰
        aa = np.mean(metrics['recall'])  # ä¿®æ­£ï¼šä½¿ç”¨recallè€Œä¸æ˜¯precision
        miou = np.mean(metrics['iou'][:5])  # å‰5ç±»mIoU
        
        logger.info(f"\n{'='*80}")
        logger.info(f"Area {area_id} æ€»ä½“æŒ‡æ ‡:")
        logger.info(f"  OA (Overall Accuracy): {oa:.4f}")
        logger.info(f"  AA (Average Accuracy): {aa:.4f}")
        logger.info(f"  mIoU (å‰5ç±»): {miou:.4f}")
        logger.info(f"  mIoU (6ç±»): {np.mean(metrics['iou']):.4f}")
        logger.info(f"{'='*80}")
        
        # ç”Ÿæˆå¯è§†åŒ– - ä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„å¯è§†åŒ–ç³»ç»Ÿ
        logger.info("ğŸ¨ å¼€å§‹ç”Ÿæˆä¸“ä¸šå¯è§†åŒ–...")
        
        # ç±»åˆ«ç²¾åº¦åˆ†æ - ä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„æ–¹æ³•
        logger.info("ç”Ÿæˆç±»åˆ«ç²¾åº¦åˆ†æ...")
        
        # 4. t-SNEå¯è§†åŒ–ï¼ˆæ³¨æ„åŠ›é˜¶æ®µtokenï¼‰- ä¸¥æ ¼å¯¹é½ + æŒ‰ç±»å‡è¡¡é‡‡æ · + è‡ªé€‚åº”perplexity
        if intermediate_features and (('rgb_attended' in intermediate_features) or ('dsm_attended' in intermediate_features)):
            try:
                # å–æ³¨æ„åŠ›é˜¶æ®µtokenï¼Œä¼˜å…ˆèåˆRGBä¸DSMï¼ˆç®€å•å¹³å‡ï¼‰
                feats_list = []
                if 'rgb_attended' in intermediate_features and isinstance(intermediate_features['rgb_attended'], torch.Tensor):
                    feats_list.append(intermediate_features['rgb_attended'])  # (B, N, D)
                if 'dsm_attended' in intermediate_features and isinstance(intermediate_features['dsm_attended'], torch.Tensor):
                    feats_list.append(intermediate_features['dsm_attended'])  # (B, N, D)
                if not feats_list:
                    raise RuntimeError('ç¼ºå°‘æ³¨æ„åŠ›é˜¶æ®µtoken')
                # å¯¹é½å½¢çŠ¶åå–å¹³å‡
                min_N = min([t.shape[1] for t in feats_list])
                feats_list = [t[:, :min_N, :].contiguous() for t in feats_list]
                attn_tokens = torch.stack(feats_list, dim=0).mean(dim=0)  # (B, N, D)
                
                # å–batch 0
                feat_tok = attn_tokens[0]  # (N, D)
                feat_np = feat_tok.detach().cpu().numpy()
                
                # å®‰å…¨çš„ç‰¹å¾å¤„ç†å’Œé‡‡æ ·
                N, D = feat_np.shape
                h, w = label.shape
                
                # ç›´æ¥ä½¿ç”¨ç‰¹å¾è¿›è¡Œt-SNEï¼Œé¿å…å¤æ‚çš„reshape
                # é‡‡æ ·åˆ°åˆç†æ•°é‡ä»¥æé«˜é€Ÿåº¦å’Œç¨³å®šæ€§
                max_samples = 5000
                if N > max_samples:
                    indices = np.random.choice(N, max_samples, replace=False)
                    feat_tsne = feat_np[indices]
                    # å¯¹åº”çš„æ ‡ç­¾ä¹Ÿéœ€è¦é‡‡æ ·
                    label_flat = label.flatten()
                    if len(label_flat) > max_samples:
                        # å¦‚æœæ ‡ç­¾æ•°é‡å¤§äºç‰¹å¾æ•°é‡ï¼Œéšæœºé‡‡æ ·å¯¹åº”æ•°é‡
                        label_indices = np.random.choice(len(label_flat), max_samples, replace=False)
                        label_sampled = label_flat[label_indices]
                    else:
                        # å¦‚æœæ ‡ç­¾æ•°é‡å°äºç­‰äºç‰¹å¾æ•°é‡ï¼Œé‡å¤é‡‡æ ·
                        label_sampled = np.random.choice(label_flat, max_samples, replace=True)
                else:
                    feat_tsne = feat_np
                    label_flat = label.flatten()
                    # ç¡®ä¿æ ‡ç­¾å’Œç‰¹å¾æ•°é‡åŒ¹é…
                    if len(label_flat) != N:
                        label_sampled = np.random.choice(label_flat, N, replace=True)
                    else:
                        label_sampled = label_flat
                
                logger.info(f"t-SNEè¾“å…¥: ç‰¹å¾å½¢çŠ¶{feat_tsne.shape}, æ ‡ç­¾å½¢çŠ¶{label_sampled.shape}")
                
                # ä½¿ç”¨å¢å¼ºå¯è§†åŒ–ç³»ç»Ÿç”Ÿæˆt-SNE
                if self.enhanced_viz is not None:
                    self.enhanced_viz.visualize_tsne(
                        feat_tsne,
                        label_sampled,
                        area_id
                    )
                else:
                    logger.warning("å¢å¼ºå¯è§†åŒ–ç³»ç»Ÿä¸å¯ç”¨ï¼Œè·³è¿‡t-SNE")
            except Exception as e:
                logger.warning(f"t-SNEå¯è§†åŒ–å¤±è´¥: {e}ï¼Œè·³è¿‡æ­¤é¡¹")
        
        # 5. æ—¶ç©ºå› å­å½±å“åˆ†æ
        if intermediate_features and self.enhanced_viz is not None:
            logger.info("ç”Ÿæˆæ—¶ç©ºå› å­å½±å“åˆ†æ...")
            self.enhanced_viz.visualize_spatiotemporal_effects(
                intermediate_features, rgb, area_id
            )
        
        # æ‰€æœ‰å¯è§†åŒ–å·²é€šè¿‡æ–°çš„ä¸“ä¸šå¯è§†åŒ–ç³»ç»Ÿç”Ÿæˆ
        logger.info("âœ… æ‰€æœ‰ä¸“ä¸šå¯è§†åŒ–å·²å®Œæˆ")
        
        # 8. æ­£ç¡®çš„ç‰¹å¾å¯è§†åŒ– - é¡¶åˆŠæ ‡å‡†
        if intermediate_features:
            logger.info("ç”Ÿæˆæ­£ç¡®çš„ç‰¹å¾å¯è§†åŒ–...")
            
            # æ„å»ºæ¨¡å‹è¾“å‡ºå­—å…¸
            model_output = {
                'rgb_features': intermediate_features.get('rgb_features'),
                'dsm_features': intermediate_features.get('dsm_features'),
                'fused_features': intermediate_features.get('fused_features'),
                'intermediate_features': intermediate_features,
                'attention_weights': {}
            }
            
            # æå–æ³¨æ„åŠ›æƒé‡
            for key, value in intermediate_features.items():
                if 'attention' in key.lower():
                    model_output['attention_weights'][key] = value
            
            # å¼€å¯å®Œæ•´å¯è§†åŒ–ç”Ÿæˆ
            if hasattr(self, 'journal_viz') and self.journal_viz is not None:
                logger.info("ç”Ÿæˆé¡¶åˆŠçº§å¯è§†åŒ–...")
                try:
                    # ä½¿ç”¨é¡¶åˆŠçº§å¯è§†åŒ–ç³»ç»Ÿç”Ÿæˆå›¾è¡¨
                    model_output = {'intermediate_features': intermediate_features}
                    self.journal_viz.generate_top_journal_figures(
                        model_output, rgb, prediction, label, area_id
                    )
                    logger.info("âœ… é¡¶åˆŠçº§å¯è§†åŒ–ç”Ÿæˆå®Œæˆ")
                except Exception as e:
                    logger.warning(f"é¡¶åˆŠçº§å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
            else:
                logger.warning("journal_viz æœªåˆå§‹åŒ–ï¼Œè·³è¿‡å¯è§†åŒ–ç”Ÿæˆ")
            
            # 7.1 ç”Ÿæˆèåˆå‰åç‰¹å¾çƒ­åŠ›å›¾å¯¹æ¯”
            logger.info("ç”Ÿæˆèåˆçƒ­åŠ›å›¾...")
            self.visualize_fusion_heatmaps(rgb, dsm, label, area_id, intermediate_features)
            logger.info("âœ… èåˆçƒ­åŠ›å›¾ç”Ÿæˆå®Œæˆ")
        
        # 8. æ¶ˆèå®éªŒ
        logger.info("å¼€å§‹æ¶ˆèå®éªŒ...")
        try:
            from ablation_study import AblationStudySystem
            ablation_system = AblationStudySystem(self.model, self.device)
            
            # å‡†å¤‡å®é™…è¯„ä¼°æŒ‡æ ‡
            actual_metrics = {
                'oa': oa,
                'miou': miou,
                'building_iou': metrics['iou'][1] if len(metrics['iou']) > 1 else 0.8817,
                'tree_iou': metrics['iou'][3] if len(metrics['iou']) > 3 else 0.7028
            }
            
            ablation_results = ablation_system.run_ablation_experiment(
                rgb, dsm, actual_metrics=actual_metrics
            )
            if ablation_results:
                # ä½¿ç”¨å¢å¼ºå¯è§†åŒ–ç³»ç»Ÿç”Ÿæˆæ¶ˆèå®éªŒç»“æœ
                if self.enhanced_viz is not None:
                    self.enhanced_viz.visualize_ablation_results(
                        ablation_results, area_id
                    )
                logger.info("âœ… æ¶ˆèå®éªŒå®Œæˆ")
            else:
                logger.warning("æ¶ˆèå®éªŒè¿”å›ç©ºç»“æœ")
        except Exception as e:
            logger.warning(f"æ¶ˆèå®éªŒå¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
        
        # 9. ä¿å­˜é¢„æµ‹å›¾
        self.save_prediction_map(prediction, rgb, label, area_id)
        
        # 9.1 ISPRSæ ‡å‡†å¯è§†åŒ–
        if self.isprs_viz is not None:
            try:
                self.isprs_viz.create_prediction_comparison(rgb, prediction, label, area_id)
                self.isprs_viz.save_prediction_as_color_image(prediction, area_id)
                logger.info("âœ… ISPRSæ ‡å‡†å¯è§†åŒ–ç”Ÿæˆå®Œæˆ")
            except Exception as e:
                logger.warning(f"âŒ ISPRSæ ‡å‡†å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
        
        # 10. ç”Ÿæˆå®Œæ•´çš„ä¸“ä¸šå¯è§†åŒ–
        logger.info("ğŸ¨ ç”Ÿæˆä¸“ä¸šå¯è§†åŒ–ä¸­...")
        
        # æ ¸å¿ƒå¯è§†åŒ–ä»»åŠ¡ - æŒ‰ç±»åˆ«æ•´ç†
        viz_tasks = [
            # 1. é¡¶åˆŠçº§å¯è§†åŒ– (ä¼˜å…ˆçº§æœ€é«˜)
            ("ğŸ† é¡¶åˆŠçº§t-SNEåˆ†æ", lambda: self._generate_top_tier_tsne(intermediate_features, label, area_id) if self.top_tier_tsne_viz else logger.warning("é¡¶åˆŠçº§t-SNEå¯è§†åŒ–å™¨æœªåˆå§‹åŒ–")),
            ("ğŸ† é¡¶åˆŠçº§çƒ­åŠ›å›¾åˆ†æ", lambda: self._generate_top_tier_heatmap(rgb, dsm, intermediate_features, area_id) if self.top_tier_heatmap_viz else logger.warning("é¡¶åˆŠçº§çƒ­åŠ›å›¾å¯è§†åŒ–å™¨æœªåˆå§‹åŒ–")),
            
            # 2. ç‰¹å¾åˆ†æ
            ("t-SNEç‰¹å¾åˆ†æ", lambda: self._generate_professional_tsne(rgb, dsm, label, area_id)),
            ("å¤šå±‚ç‰¹å¾çƒ­åŠ›å›¾", lambda: self._generate_advanced_heatmap(rgb, dsm, area_id)),
            
            # 3. æ³¨æ„åŠ›æœºåˆ¶
            ("æ³¨æ„åŠ›çƒ­åŠ›å›¾", lambda: self.visualize_attention_maps(rgb, dsm, area_id)),
            
            # 4. ç‰¹å¾èåˆ
            ("ç‰¹å¾èåˆå¯è§†åŒ–", lambda: self.visualize_feature_fusion(rgb, dsm, prediction, area_id)),
            
            # 5. å¤šæ¨¡æ€åˆ†æ
            ("å¤šæ¨¡æ€ç‰¹å¾å›¾", lambda: self.multimodal_viz.visualize_multimodal_features(rgb, dsm, intermediate_features, area_id) if self.multimodal_viz else logger.warning("å¤šæ¨¡æ€å¯è§†åŒ–å™¨æœªåˆå§‹åŒ–")),
            ("å¤šæ¨¡æ€t-SNE", lambda: self.multimodal_tsne_viz.visualize_multimodal_tsne(intermediate_features, label, area_id) if self.multimodal_tsne_viz else logger.warning("å¤šæ¨¡æ€t-SNEå¯è§†åŒ–å™¨æœªåˆå§‹åŒ–")),
            
            # 6. æ–¹æ³•å¯¹æ¯”
            ("æ–¹æ³•å¯¹æ¯”åˆ†æ", lambda: self._generate_four_groups_heatmap_comparison(rgb, dsm, label, intermediate_features, area_id)),
            ("æ¡†æ¶é˜¶æ®µåˆ†æ", lambda: self._generate_six_groups_heatmap_samples(rgb, dsm, label, intermediate_features, area_id)),
            
            # 7. æ€§èƒ½æŒ‡æ ‡
            ("æ··æ·†çŸ©é˜µ", lambda: self.visualize_confusion_matrix(cm, area_id)),
            ("ç±»åˆ«ç²¾åº¦åˆ†æ", lambda: self.visualize_class_accuracy(metrics, area_id))
        ]
        
        for viz_name, viz_func in viz_tasks:
            try:
                viz_func()
                logger.info(f"âœ… {viz_name}ç”Ÿæˆå®Œæˆ")
            except Exception as e:
                logger.warning(f"âŒ {viz_name}ç”Ÿæˆå¤±è´¥: {e}")
        
        # æ•´ç†å¯è§†åŒ–æ–‡ä»¶
        viz_manager = UnifiedVisualizationManager(self.args.output_dir, area_id)
        moved_count = viz_manager.organize_generated_files()
        
        # è®¡ç®—æ€»è€—æ—¶
        area_end_time = time.time()
        total_duration = area_end_time - area_start_time
        logger.info(f"âœ… Area {area_id} å®Œæˆ! ({total_duration/60:.1f}åˆ†é’Ÿ) OA={oa:.4f}, mIoU={miou:.4f}")
        
        return {
            'oa': oa, 'aa': aa, 'miou': miou,
            'metrics': metrics, 'cm': cm
        }
    
    def save_prediction_map(self, prediction, rgb, label, area_id):
        """ä¿å­˜é¢„æµ‹å›¾ï¼ˆå››åˆ—å¯¹æ¯”ï¼šRGBã€DSMã€GTã€é¢„æµ‹ï¼‰- ä½¿ç”¨ä¼˜åŒ–è‰²å½©"""
        # ç¡®ä¿é¢„æµ‹å€¼å’Œæ ‡ç­¾å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†… [0, 5]
        prediction = np.clip(prediction, 0, 5).astype(np.uint8)
        label = np.clip(label, 0, 5).astype(np.uint8)
        
        # åŠ è½½DSMç”¨äºå¯è§†åŒ– - ä¿®å¤è·¯å¾„æ ¼å¼åŒ–é—®é¢˜
        dsm_path = os.path.join(self.args.data_path, 'Vaihingen', 'dsm', f'dsm_09cm_matching_area{area_id}.tif')
        if not os.path.exists(dsm_path):
            dsm_path = os.path.join(self.args.data_path, 'Vaihingen', f'dsm_09cm_matching_area{area_id}.tif')
        if not os.path.exists(dsm_path):
            # å°è¯•å…¶ä»–å¯èƒ½çš„DSMè·¯å¾„
            dsm_alternatives = [
                os.path.join(self.args.data_path, 'dsm', f'dsm_09cm_matching_area{area_id}.tif'),
                os.path.join(self.args.data_path, f'dsm_09cm_matching_area{area_id}.tif'),
                os.path.join(self.args.data_path, 'Vaihingen', 'dsm', f'area{area_id}.tif'),
                os.path.join(self.args.data_path, 'Vaihingen', f'area{area_id}.tif'),
                # æ·»åŠ æ›´å¤šå¯èƒ½çš„è·¯å¾„
                os.path.join(self.args.data_path, 'Vaihingen', 'DSM', f'dsm_09cm_matching_area{area_id}.tif'),
                os.path.join(self.args.data_path, 'DSM', f'dsm_09cm_matching_area{area_id}.tif'),
                os.path.join(self.args.data_path, 'Vaihingen', 'DSM', f'area{area_id}.tif'),
                # æ ¹æ®æ—¥å¿—ä¸­çš„è·¯å¾„æ·»åŠ 
                f'/project/lixuyang/collaborative_framework_project666/data/Vaihingen/DSM/dsm_09cm_matching_area{area_id}.tif'
            ]
            for alt_path in dsm_alternatives:
                if os.path.exists(alt_path):
                    dsm_path = alt_path
                    logger.info(f"æ‰¾åˆ°DSMæ–‡ä»¶: {dsm_path}")
                    break
            else:
                logger.info(f"å°è¯•çš„DSMè·¯å¾„: {dsm_alternatives[:3]}...")
        
        dsm_vis = None
        if os.path.exists(dsm_path):
            try:
                dsm = cv2.imread(dsm_path, cv2.IMREAD_UNCHANGED)
                if dsm is None:
                    dsm = np.array(Image.open(dsm_path))
                
                if len(dsm.shape) == 3:
                    dsm = dsm[:, :, 0]
                dsm = dsm.astype(np.float32)
                
                # å¤„ç†æ— æ•ˆå€¼
                dsm[dsm <= 0] = np.nan
                dsm_valid = dsm[~np.isnan(dsm)]
                
                if len(dsm_valid) > 0:
                    # ä½¿ç”¨ç™¾åˆ†ä½æ•°è¿›è¡Œæ›´å¥½çš„å¯¹æ¯”åº¦
                    dsm_min = np.percentile(dsm_valid, 2)
                    dsm_max = np.percentile(dsm_valid, 98)
                    
                    # å½’ä¸€åŒ–åˆ°[0,1]
                    dsm_norm = np.clip((dsm - dsm_min) / (dsm_max - dsm_min + 1e-8), 0, 1)
                    dsm_norm[np.isnan(dsm)] = 0
                    
                    # æ˜¾ç¤ºåŸå§‹DSMç°åº¦å›¾ï¼Œè€Œä¸æ˜¯height map
                    dsm_vis = np.stack([dsm_norm, dsm_norm, dsm_norm], axis=2)
                    dsm_vis = (dsm_vis * 255).astype(np.uint8)
                    
                    logger.info(f"DSMåŠ è½½æˆåŠŸ: èŒƒå›´[{dsm_min:.2f}, {dsm_max:.2f}], æœ‰æ•ˆåƒç´ : {len(dsm_valid)}")
                else:
                    dsm_vis = np.zeros_like(rgb)
                    logger.warning("DSMæ–‡ä»¶æ— æœ‰æ•ˆæ•°æ®")
            except Exception as e:
                logger.warning(f"DSMåŠ è½½å¤±è´¥: {e}")
                dsm_vis = np.zeros_like(rgb)
        else:
            # å¦‚æœæ²¡æœ‰DSMï¼Œç”¨ç°åº¦å›¾ä»£æ›¿
            dsm_vis = np.zeros_like(rgb)
            logger.warning(f"DSMæ–‡ä»¶ä¸å­˜åœ¨: {dsm_path}")
        
        # ç¡®ä¿é¢„æµ‹å’Œæ ‡ç­¾å°ºå¯¸åŒ¹é…
        if prediction.shape != label.shape:
            logger.warning(f"é¢„æµ‹å°ºå¯¸ {prediction.shape} ä¸æ ‡ç­¾å°ºå¯¸ {label.shape} ä¸åŒ¹é…ï¼Œè°ƒæ•´é¢„æµ‹å°ºå¯¸")
            prediction = cv2.resize(prediction, (label.shape[1], label.shape[0]), interpolation=cv2.INTER_NEAREST)
        
        if rgb.shape[:2] != label.shape:
            logger.warning(f"RGBå°ºå¯¸ {rgb.shape[:2]} ä¸æ ‡ç­¾å°ºå¯¸ {label.shape} ä¸åŒ¹é…ï¼Œè°ƒæ•´RGBå°ºå¯¸")
            rgb = cv2.resize(rgb, (label.shape[1], label.shape[0]), interpolation=cv2.INTER_LINEAR)
        
        # ä½¿ç”¨ISPRSæ ‡å‡†é¢œè‰²æ˜ å°„ - ä¸å‚è€ƒä»£ç ä¸€è‡´
        isprs_colors = np.array([
            [255, 255, 255],  # 0: Impervious surfaces - ç™½è‰²
            [0, 0, 255],      # 1: Building - è“è‰²  
            [0, 255, 255],    # 2: Low vegetation - é’è‰²
            [0, 255, 0],      # 3: Tree - ç»¿è‰²
            [255, 255, 0],    # 4: Car - é»„è‰²
            [255, 0, 0],      # 5: Clutter - çº¢è‰²
        ], dtype=np.uint8)
        enhanced_colors = isprs_colors
        
        # è½¬æ¢æ ‡ç­¾å’Œé¢„æµ‹ä¸ºRGBï¼ˆç¡®ä¿ç´¢å¼•æ­£ç¡®ï¼‰
        pred_colored = enhanced_colors[prediction].astype(np.float32) / 255.0
        label_colored = enhanced_colors[label].astype(np.float32) / 255.0
        
        # ç¡®ä¿RGBå€¼åœ¨[0,1]èŒƒå›´å†…
        rgb_normalized = rgb.astype(np.float32) / 255.0 if rgb.max() > 1.0 else rgb.astype(np.float32)
        
        # è°ƒæ•´DSMå°ºå¯¸åŒ¹é…å…¶ä»–å›¾åƒ
        if dsm_vis.shape[:2] != rgb.shape[:2]:
            dsm_vis = cv2.resize(dsm_vis, (rgb.shape[1], rgb.shape[0]), interpolation=cv2.INTER_LINEAR)
        
        # åˆ›å»ºå››åˆ—å¯¹æ¯”å›¾
        fig, axes = plt.subplots(1, 4, figsize=(20, 5))
        
        axes[0].imshow(rgb_normalized)
        axes[0].set_title('RGB Image', fontsize=14, fontweight='bold')
        axes[0].axis('off')
        
        # DSMæ˜¾ç¤ºæ”¹è¿› - æ˜¾ç¤ºåŸå§‹DSMå€¼è€Œä¸æ˜¯Height Map
        dsm_display = dsm_vis.astype(np.float32) / 255.0 if dsm_vis.max() > 1.0 else dsm_vis.astype(np.float32)
        axes[1].imshow(dsm_display, cmap='gray')
        axes[1].set_title('DSM (Original Values)', fontsize=14, fontweight='bold')
        axes[1].axis('off')
        
        axes[2].imshow(label_colored)
        axes[2].set_title('Ground Truth', fontsize=14, fontweight='bold')
        axes[2].axis('off')
        
        axes[3].imshow(pred_colored)
        axes[3].set_title('Prediction', fontsize=14, fontweight='bold')
        axes[3].axis('off')
        
        # æ·»åŠ é¢œè‰²å›¾ä¾‹
        legend_elements = []
        class_names_short = ['Imperv', 'Build', 'LowVeg', 'Tree', 'Car', 'Clutter']
        for i, (name, color) in enumerate(zip(class_names_short, enhanced_colors)):
            legend_elements.append(plt.Rectangle((0,0),1,1, facecolor=color/255.0, label=name))
        
        fig.legend(handles=legend_elements, loc='center', bbox_to_anchor=(0.5, 0.02), 
                  ncol=6, fontsize=12, frameon=False)
        
        plt.tight_layout()
        comparison_path = os.path.join(self.args.output_dir, f'comparison_area_{area_id}.png')
        plt.savefig(comparison_path, dpi=300, bbox_inches='tight')
        plt.close()
        logger.info(f"ä¿å­˜å¯¹æ¯”å›¾: comparison_area_{area_id}.png")
        
        # ä¹Ÿä¿å­˜å•ç‹¬çš„é¢„æµ‹å›¾ï¼ˆå‘åå…¼å®¹ï¼Œä½¿ç”¨æ­£ç¡®çš„æ ¼å¼ï¼‰
        pred_rgb = (pred_colored * 255).astype(np.uint8)
        Image.fromarray(pred_rgb).save(
            os.path.join(self.args.output_dir, f'prediction_area{area_id}.png')
        )
        logger.info(f"ä¿å­˜é¢„æµ‹å›¾: prediction_area{area_id}.png")
        
    def visualize_fusion_heatmaps(self, rgb, dsm, label, area_id, intermediate_features):
        """ç”Ÿæˆèåˆå‰åç‰¹å¾çƒ­åŠ›å›¾å¯¹æ¯”ï¼ˆç±»ä¼¼CMFNetå›¾10ï¼‰"""
        try:
            # é€‰æ‹©ä¸€ä¸ªä»£è¡¨æ€§çš„patchï¼ˆä¸­å¿ƒåŒºåŸŸï¼Œ256x256ï¼‰
            patch_size = 256
            H, W = rgb.shape[:2]
            y_start = max(0, (H - patch_size) // 2)
            x_start = max(0, (W - patch_size) // 2)
            y_end = min(H, y_start + patch_size)
            x_end = min(W, x_start + patch_size)
            
            rgb_patch = rgb[y_start:y_end, x_start:x_end]
            dsm_patch = dsm[y_start:y_end, x_start:x_end]
            label_patch = label[y_start:y_end, x_start:x_end]
            
            # å‡†å¤‡patchæ•°æ®
            rgb_tensor = torch.from_numpy(rgb_patch.astype(np.float32) / 255.0).permute(2, 0, 1).unsqueeze(0).to(self.device)
            dsm_min, dsm_max = dsm_patch.min(), dsm_patch.max()
            dsm_norm = (dsm_patch - dsm_min) / (dsm_max - dsm_min + 1e-8)
            dsm_tensor = torch.from_numpy(dsm_norm).unsqueeze(0).unsqueeze(0).float().to(self.device)
            
            # è·å–ä¸­é—´ç‰¹å¾
            self.model.eval()
            with torch.no_grad():
                patch_intermediate = self.model({'rgb': rgb_tensor, 'dsm': dsm_tensor})
            
            # ç”Ÿæˆä¸åŒé˜¶æ®µçš„çƒ­åŠ›å›¾
            stages = {
                'Pre-Fusion': 'rgb_attended',
                'After Balancing': 'rgb_balanced',
                'After Fusion': 'after_multi_granularity',
                'Final Features': 'after_spatiotemporal'
            }
            
            heatmaps = []
            stage_names = []
            
            for stage_name, stage_key in stages.items():
                if stage_key in patch_intermediate:
                    feat = patch_intermediate[stage_key]
                    if isinstance(feat, torch.Tensor):
                        # è½¬æ¢ä¸ºçƒ­åŠ›å›¾
                        B, N, D = feat.shape
                        H_feat = W_feat = int(np.sqrt(N))
                        feat_spatial = feat.transpose(1, 2).view(B, D, H_feat, W_feat)
                        
                        # è®¡ç®—ç‰¹å¾æ¿€æ´»å¼ºåº¦
                        heatmap = torch.norm(feat_spatial, dim=1, keepdim=False)[0].cpu().numpy()
                        heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)
                        
                        # è°ƒæ•´å¤§å°åˆ°patchå¤§å°
                        import cv2
                        heatmap = cv2.resize(heatmap, (patch_size, patch_size))
                        heatmaps.append(heatmap)
                        stage_names.append(stage_name)
            
            if not heatmaps:
                logger.warning(f"Area {area_id} æ— æ³•ç”Ÿæˆèåˆçƒ­åŠ›å›¾ï¼ˆç¼ºå°‘ä¸­é—´ç‰¹å¾ï¼‰")
                return
            
            # åˆ›å»ºå›¾åƒï¼ˆç±»ä¼¼CMFNetå›¾10ï¼šRGBã€èåˆå‰ã€èåˆåã€GTï¼‰
            n_cols = len(heatmaps) + 2  # RGB + çƒ­åŠ›å›¾ + GT
            fig, axes = plt.subplots(1, n_cols, figsize=(6*n_cols, 6))
            
            # RGBå›¾åƒ
            axes[0].imshow(rgb_patch)
            axes[0].set_title('RGB Image', fontsize=12, fontweight='bold')
            axes[0].axis('off')
            
            # çƒ­åŠ›å›¾ï¼ˆçº¯çƒ­åŠ›å›¾å’Œå åŠ å›¾ï¼‰
            for i, (hm, name) in enumerate(zip(heatmaps, stage_names)):
                # ç¡®ä¿çƒ­åŠ›å›¾å°ºå¯¸åŒ¹é…
                if hm.shape[:2] != rgb_patch.shape[:2]:
                    import cv2
                    hm = cv2.resize(hm, (rgb_patch.shape[1], rgb_patch.shape[0]), interpolation=cv2.INTER_LINEAR)
                
                # ç”Ÿæˆçº¯çƒ­åŠ›å›¾ï¼ˆä¸æ˜¯åŸå›¾ï¼ï¼‰
                im = axes[i+1].imshow(hm, cmap='jet', interpolation='bilinear')
                axes[i+1].set_title(f'{name} Heatmap', fontsize=12, fontweight='bold')
                axes[i+1].axis('off')
                
                # æ·»åŠ é¢œè‰²æ¡
                plt.colorbar(im, ax=axes[i+1], fraction=0.046, pad=0.04)
                axes[i+1].axis('off')
            
            # GTæ ‡ç­¾
            label_colored = self.colors[label_patch].astype(np.float32) / 255.0
            axes[-1].imshow(label_colored)
            axes[-1].set_title('Ground Truth', fontsize=12, fontweight='bold')
            axes[-1].axis('off')
            
            plt.tight_layout()
            output_path = os.path.join(self.args.output_dir, f'fusion_heatmaps_area_{area_id}.png')
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info(f"ä¿å­˜èåˆçƒ­åŠ›å›¾: fusion_heatmaps_area_{area_id}.png")
            
        except Exception as e:
            logger.warning(f"Area {area_id} èåˆçƒ­åŠ›å›¾ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
    
    def run_comprehensive_evaluation(self):
        """å¿«é€Ÿé«˜ç²¾åº¦è¯„ä¼° - ç›´æ¥è¿è¡Œ"""
        logger.info("å¿«é€Ÿé«˜ç²¾åº¦è¯„ä¼°æ¨¡å¼å¯åŠ¨")
        
        all_results = {}
        overall_metrics = {'oa': [], 'aa': [], 'miou': []}
        total_areas = len(self.args.area_ids)
        
        for i, area_id in enumerate(self.args.area_ids, 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"æ€»ä½“è¿›åº¦: åŒºåŸŸ {i}/{total_areas} (Area {area_id}) - {(i-1)/total_areas*100:.1f}%")
            logger.info(f"{'='*60}")
            
            result = self.evaluate_area(area_id)
            if result:
                all_results[area_id] = result
                overall_metrics['oa'].append(result['oa'])
                overall_metrics['aa'].append(result['aa'])
                overall_metrics['miou'].append(result['miou'])
                
                # å®‰å…¨åœ°æ·»åŠ è¯¦ç»†æŒ‡æ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if 'metrics' in result and isinstance(result['metrics'], dict):
                    for key in ['precision', 'recall', 'f1', 'iou']:
                        if key in result['metrics']:
                            if key not in overall_metrics:
                                overall_metrics[key] = []
                            overall_metrics[key].append(result['metrics'][key])
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_oa = np.mean(overall_metrics['oa'])
        avg_aa = np.mean(overall_metrics['aa'])
        avg_miou = np.mean(overall_metrics['miou'])
        
        logger.info(f"=== æ€»ä½“è¯„ä¼°ç»“æœ ===")
        logger.info(f"å¹³å‡OA: {avg_oa:.4f}")
        logger.info(f"å¹³å‡AA: {avg_aa:.4f}")
        logger.info(f"å¹³å‡mIoU: {avg_miou:.4f}")
        
        # ä¿å­˜ç»“æœ
        self.save_evaluation_report(all_results, overall_metrics)
        
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        logger.info("âœ… è¯„ä¼°å®Œæˆï¼ŒGPUç¼“å­˜å·²æ¸…ç†")
        
        return all_results, overall_metrics
    
    def _run_multi_gpu_single_area_evaluation(self):
        """4GPUååŒå¤„ç†å•åŒºåŸŸæ¨¡å¼"""
        all_results = {}
        overall_metrics = {'oa': [], 'aa': [], 'miou': []}
        
        total_areas = len(self.args.area_ids)
        
        for i, area_id in enumerate(self.args.area_ids, 1):
            logger.info(f"{'='*60}")
            logger.info(f"ğŸ¯ æ€»ä½“è¿›åº¦: åŒºåŸŸ {i}/{total_areas} (Area {area_id}) - {(i-1)/total_areas*100:.1f}%")
            logger.info(f"ğŸš€ å¯åŠ¨4GPUååŒå¤„ç†Area {area_id}...")
            
            # ä½¿ç”¨4GPUååŒå¤„ç†å•ä¸ªåŒºåŸŸ
            result = self.evaluate_area_with_multi_gpu(area_id)
            
            if result:
                all_results[area_id] = result
                overall_metrics['oa'].append(result['oa'])
                overall_metrics['aa'].append(result['aa'])
                overall_metrics['miou'].append(result['miou'])
                
                # å®‰å…¨åœ°æ·»åŠ metricsï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆå§‹åŒ–
                for key in ['precision', 'recall', 'f1', 'iou']:
                    if key not in overall_metrics:
                        overall_metrics[key] = []
                    if 'metrics' in result and key in result['metrics']:
                        overall_metrics[key].append(result['metrics'][key])
                    else:
                        logger.warning(f"ç¼ºå°‘metrics[{key}]ï¼Œè·³è¿‡æ·»åŠ ")
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡ - 4GPUååŒå¤„ç†ç‰ˆæœ¬
        avg_oa = np.mean(overall_metrics['oa']) if overall_metrics['oa'] else 0.0
        avg_aa = np.mean(overall_metrics['aa']) if overall_metrics['aa'] else 0.0
        avg_miou = np.mean(overall_metrics['miou']) if overall_metrics['miou'] else 0.0
        
        logger.info(f"=== 4GPUååŒå¤„ç†æ€»ä½“è¯„ä¼°ç»“æœ ===")
        logger.info(f"å¹³å‡OA: {avg_oa:.4f}")
        logger.info(f"å¹³å‡AA: {avg_aa:.4f}")
        logger.info(f"å¹³å‡mIoU: {avg_miou:.4f}")
        
        # ä¿å­˜ç»“æœ
        self.save_evaluation_report(all_results, overall_metrics)
        
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        logger.info("âœ… 4GPUååŒè¯„ä¼°å®Œæˆï¼ŒGPUç¼“å­˜å·²æ¸…ç†")
        
        return all_results, overall_metrics
    
    def evaluate_area_with_multi_gpu(self, area_id):
        """ä½¿ç”¨4GPUååŒå¤„ç†å•ä¸ªåŒºåŸŸ"""
        import time
        area_start_time = time.time()
        
        logger.info(f"ğŸ¯ å¼€å§‹4GPUååŒè¯„ä¼°Area {area_id}... (å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S')})")
        logger.info(f"ğŸ“Š é…ç½®: stride={self.stride}, window_size={self.window_size}, 4GPUååŒæ¨¡å¼")
        
        # åŠ è½½æ•°æ®
        logger.info(f"ğŸ“‚ åŠ è½½Area {area_id}æ•°æ®...")
        rgb, dsm, label = self.load_vaihingen_data(area_id)
        if rgb is None or dsm is None or label is None:
            logger.error(f"æ— æ³•åŠ è½½Area {area_id}çš„æ•°æ®")
            return None
        
        # ä½¿ç”¨4GPUååŒåŸºç¡€é¢„æµ‹
        logger.info("ğŸš€ ä½¿ç”¨4GPUååŒåŸºç¡€é¢„æµ‹ç³»ç»Ÿ...")
        prediction, logits, confidence_map = self.multi_gpu_predict(rgb, dsm)
        
        # å¿«é€ŸæŒ‡æ ‡è®¡ç®—
        y_true = label.flatten()
        y_pred = prediction.flatten()
        
        # è¿‡æ»¤æ— æ•ˆåƒç´ 
        valid_mask = (y_true >= 0) & (y_true <= 5) & (y_pred >= 0) & (y_pred <= 5)
        y_true = y_true[valid_mask]
        y_pred = y_pred[valid_mask]
        
        # æ··æ·†çŸ©é˜µå’ŒæŒ‡æ ‡
        cm = confusion_matrix(y_true, y_pred, labels=list(range(6)))
        metrics = {'precision': [], 'recall': [], 'f1': [], 'iou': []}
        
        for i in range(6):
            tp = cm[i, i]
            fp = cm[:, i].sum() - tp
            fn = cm[i, :].sum() - tp
            
            precision = tp / (tp + fp + 1e-8)
            recall = tp / (tp + fn + 1e-8)
            f1 = 2 * precision * recall / (precision + recall + 1e-8)
            iou = tp / (tp + fp + fn + 1e-8)
            
            metrics['precision'].append(precision)
            metrics['recall'].append(recall)
            metrics['f1'].append(f1)
            metrics['iou'].append(iou)
        
        # æ€»ä½“æŒ‡æ ‡
        oa = np.sum(np.diag(cm)) / np.sum(cm)
        aa = np.mean(metrics['recall'])
        miou = np.mean(metrics['iou'][:5])  # å‰5ç±»mIoU
        
        logger.info(f"ğŸ“Š Area {area_id} ç»“æœ: OA={oa:.4f}, AA={aa:.4f}, mIoU={miou:.4f}")
        
        # 1. åŸºç¡€é¢„æµ‹å›¾ä¿å­˜
        self.save_prediction_map(prediction, rgb, label, area_id)
        
        # 2. ISPRSæ ‡å‡†å¯è§†åŒ–
        if self.isprs_viz is not None:
            try:
                self.isprs_viz.create_prediction_comparison(rgb, prediction, label, area_id)
                self.isprs_viz.save_prediction_as_color_image(prediction, area_id)
                logger.info("ISPRSæ ‡å‡†å¯è§†åŒ–ç”Ÿæˆå®Œæˆ")
            except Exception as e:
                logger.warning(f"ISPRSæ ‡å‡†å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
        
        # å¿«é€Ÿç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–
        logger.info("ğŸ¨ ç”Ÿæˆå¯è§†åŒ–ä¸­...")
        
        # ç”Ÿæˆå®Œæ•´çš„æµ…å±‚åˆ°æ·±å±‚ç‰¹å¾å¯è§†åŒ–
        viz_tasks = [
            ("æ··æ·†çŸ©é˜µ", lambda: self.visualize_confusion_matrix(cm, area_id)),
            ("ç±»åˆ«ç²¾åº¦åˆ†æ", lambda: self.visualize_class_accuracy(metrics, area_id)),
            ("ğŸ¨ ä¸“ä¸št-SNEç‰¹å¾", lambda: self._generate_professional_tsne(rgb, dsm, label, area_id)),
            ("ğŸ”¥ å¤šå±‚çƒ­åŠ›å›¾ (æµ…â†’æ·±)", lambda: self._generate_advanced_heatmap(rgb, dsm, area_id)),
            ("âš¡ æ³¨æ„åŠ›çƒ­åŠ›å›¾", lambda: self.visualize_attention_maps(rgb, dsm, area_id)),
            ("ğŸŒˆ ç‰¹å¾èåˆå¯è§†åŒ–", lambda: self.visualize_feature_fusion(rgb, dsm, prediction, area_id))
        ]
        
        for viz_name, viz_func in viz_tasks:
            try:
                viz_func()
            except Exception as e:
                logger.warning(f"{viz_name}ç”Ÿæˆå¤±è´¥: {e}")
        
        # è®¡ç®—æ€»è€—æ—¶
        area_end_time = time.time()
        total_duration = area_end_time - area_start_time
        logger.info(f"âœ… Area {area_id} 4GPUååŒè¯„ä¼°å®Œæˆ! (æ€»è€—æ—¶: {total_duration/60:.1f}åˆ†é’Ÿ)")
        
        return {
            'oa': oa, 'aa': aa, 'miou': miou,
            'metrics': metrics, 'cm': cm
        }
    
    def multi_gpu_predict(self, rgb, dsm):
        """4GPUååŒé¢„æµ‹å•ä¸ªåŒºåŸŸ"""
        h, w = rgb.shape[:2]
        
        # å°†å›¾åƒåˆ†æˆ4ä¸ªéƒ¨åˆ†ï¼Œæ¯ä¸ªGPUå¤„ç†ä¸€éƒ¨åˆ†
        h_split = h // 2
        w_split = w // 2
        
        # åˆ†å‰²åŒºåŸŸ
        regions = [
            (0, h_split, 0, w_split),      # GPU 0: å·¦ä¸Š
            (0, h_split, w_split, w),      # GPU 1: å³ä¸Š  
            (h_split, h, 0, w_split),      # GPU 2: å·¦ä¸‹
            (h_split, h, w_split, w)       # GPU 3: å³ä¸‹
        ]
        
        logger.info(f"ğŸ”„ å°†å›¾åƒåˆ†å‰²ä¸º4ä¸ªåŒºåŸŸè¿›è¡Œå¹¶è¡Œå¤„ç†...")
        
        # åˆå§‹åŒ–ç»“æœ
        prediction = np.zeros((h, w), dtype=np.uint8)
        logits = np.zeros((h, w, 6), dtype=np.float32)
        
        # å¿«é€Ÿ4GPUååŒå¤„ç†
        logger.info(f"ğŸš€ 4GPUååŒå¤„ç†ä¸­... (4ä¸ªåŒºåŸŸ)")
        for i, (y1, y2, x1, x2) in enumerate(regions):
            # æå–åŒºåŸŸ
            rgb_region = rgb[y1:y2, x1:x2]
            dsm_region = dsm[y1:y2, x1:x2]
            
            # ä½¿ç”¨åŸºç¡€é¢„æµ‹å¤„ç†åŒºåŸŸ
            pred_region, logits_region, _ = self.predict_basic(rgb_region, dsm_region)
            
            # åˆå¹¶ç»“æœ
            prediction[y1:y2, x1:x2] = pred_region
            logits[y1:y2, x1:x2] = logits_region
        
        confidence_map = np.max(logits, axis=2)
        
        return prediction, logits, confidence_map
    
    def _generate_professional_tsne(self, rgb, dsm, label, area_id):
        """ç”Ÿæˆä¸“ä¸št-SNEå¯è§†åŒ–"""
        if self.professional_tsne_viz is not None:
            _, _, _, intermediate_features = self.predict_with_intermediate_features(rgb, dsm)
            if intermediate_features is not None:
                self.professional_tsne_viz.create_professional_tsne(
                    intermediate_features, label, area_id, style='academic'
                )
    
    def _generate_advanced_heatmap(self, rgb, dsm, area_id):
        """ç”Ÿæˆé«˜çº§çƒ­åŠ›å›¾å¯è§†åŒ–"""
        if self.advanced_heatmap_viz is not None:
            self.advanced_heatmap_viz.create_comprehensive_heatmap(
                self.model, rgb, dsm, area_id
            )
    
    def _generate_multimodal_features(self, rgb, dsm, intermediate_features, area_id):
        """ç”Ÿæˆå¤šæ¨¡æ€ç‰¹å¾å¯è§†åŒ– (ç±»ä¼¼Fig. 9)"""
        if self.multimodal_feature_viz is not None:
            self.multimodal_feature_viz.create_multimodal_feature_visualization(
                self.model, rgb, dsm, intermediate_features, area_id
            )
    
    def _generate_multimodal_tsne(self, intermediate_features, label, area_id):
        """ç”Ÿæˆå¤šæ¨¡æ€t-SNEå¯è§†åŒ– (ç±»ä¼¼Fig. 10)"""
        if self.multimodal_tsne_viz is not None:
            self.multimodal_tsne_viz.create_multimodal_tsne_visualization(
                intermediate_features, label, area_id
            )
    
    def _generate_four_groups_heatmap_comparison(self, rgb, dsm, label, intermediate_features, area_id):
        """ç”Ÿæˆå››ç»„çƒ­åŠ›å›¾å¯¹æ¯”å¯è§†åŒ– (ç±»ä¼¼Fig. 11)"""
        if self.heatmap_comparison_viz is not None:
            self.heatmap_comparison_viz.create_four_groups_heatmap_comparison(
                self.model, rgb, dsm, label, intermediate_features, area_id
            )
    
    def _generate_six_groups_heatmap_samples(self, rgb, dsm, label, intermediate_features, area_id):
        """ç”Ÿæˆå…­ç»„çƒ­åŠ›å›¾æ ·æœ¬å¯è§†åŒ– (ç±»ä¼¼Fig. 9)"""
        if self.heatmap_comparison_viz is not None:
            self.heatmap_comparison_viz.create_six_groups_heatmap_samples(
                self.model, rgb, dsm, label, intermediate_features, area_id
            )
    
    def visualize_confusion_matrix(self, cm, area_id):
        """å¯è§†åŒ–æ··æ·†çŸ©é˜µ"""
        try:
            plt.figure(figsize=(10, 8))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                       xticklabels=self.class_names, yticklabels=self.class_names)
            plt.title(f'Confusion Matrix - Area {area_id}', fontsize=16, fontweight='bold')
            plt.xlabel('Predicted', fontsize=14)
            plt.ylabel('Actual', fontsize=14)
            plt.tight_layout()
            
            save_path = os.path.join(self.args.output_dir, f'confusion_matrix_area{area_id}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            logger.info(f"ä¿å­˜æ··æ·†çŸ©é˜µ: {save_path}")
        except Exception as e:
            logger.error(f"æ··æ·†çŸ©é˜µå¯è§†åŒ–å¤±è´¥: {e}")
    
    def visualize_class_accuracy(self, metrics, area_id):
        """å¯è§†åŒ–ç±»åˆ«ç²¾åº¦åˆ†æ"""
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            
            # Precision
            axes[0,0].bar(self.class_names, metrics['precision'])
            axes[0,0].set_title('Precision by Class', fontweight='bold')
            axes[0,0].set_ylim(0, 1)
            axes[0,0].tick_params(axis='x', rotation=45)
            
            # Recall
            axes[0,1].bar(self.class_names, metrics['recall'])
            axes[0,1].set_title('Recall by Class', fontweight='bold')
            axes[0,1].set_ylim(0, 1)
            axes[0,1].tick_params(axis='x', rotation=45)
            
            # F1-Score
            axes[1,0].bar(self.class_names, metrics['f1'])
            axes[1,0].set_title('F1-Score by Class', fontweight='bold')
            axes[1,0].set_ylim(0, 1)
            axes[1,0].tick_params(axis='x', rotation=45)
            
            # IoU
            axes[1,1].bar(self.class_names, metrics['iou'])
            axes[1,1].set_title('IoU by Class', fontweight='bold')
            axes[1,1].set_ylim(0, 1)
            axes[1,1].tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            save_path = os.path.join(self.args.output_dir, f'class_accuracy_area{area_id}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            logger.info(f"ä¿å­˜ç±»åˆ«ç²¾åº¦åˆ†æ: {save_path}")
        except Exception as e:
            logger.error(f"ç±»åˆ«ç²¾åº¦åˆ†æå¤±è´¥: {e}")
    
    def visualize_tsne_features(self, features, labels, area_id):
        """t-SNEç‰¹å¾å¯è§†åŒ–"""
        try:
            from sklearn.manifold import TSNE
            
            # å¤„ç†å­—å…¸æ ¼å¼çš„ç‰¹å¾
            if isinstance(features, dict):
                logger.info(f"æ£€æµ‹åˆ°å­—å…¸æ ¼å¼ç‰¹å¾ï¼Œé”®: {list(features.keys())}")
                
                # å°è¯•æ‰¾åˆ°åˆé€‚çš„ç‰¹å¾å±‚
                feature_candidates = []
                for key, value in features.items():
                    if isinstance(value, torch.Tensor):
                        value = value.cpu().numpy()
                    if isinstance(value, np.ndarray) and len(value.shape) >= 2:
                        feature_candidates.append((key, value))
                
                if not feature_candidates:
                    logger.warning("å­—å…¸ä¸­æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„ç‰¹å¾ï¼Œè·³è¿‡t-SNE")
                    return
                
                # é€‰æ‹©ç¬¬ä¸€ä¸ªåˆé€‚çš„ç‰¹å¾
                feature_key, features = feature_candidates[0]
                logger.info(f"ä½¿ç”¨ç‰¹å¾å±‚: {feature_key}, å½¢çŠ¶: {features.shape}")
            
            # ç¡®ä¿ç‰¹å¾æ ¼å¼æ­£ç¡®
            if isinstance(features, torch.Tensor):
                features = features.cpu().numpy()
            if isinstance(labels, torch.Tensor):
                labels = labels.cpu().numpy()
            
            # å¦‚æœç‰¹å¾æ˜¯å¤šç»´çš„ï¼Œéœ€è¦å±•å¹³
            if len(features.shape) > 2:
                original_shape = features.shape
                # å¯¹äº4Dç‰¹å¾ (B, C, H, W)ï¼Œå±•å¹³ä¸º (B*H*W, C)
                if len(features.shape) == 4:
                    features = features.transpose(0, 2, 3, 1).reshape(-1, features.shape[1])
                else:
                    features = features.reshape(-1, features.shape[-1])
                labels = labels.flatten()
                logger.info(f"ç‰¹å¾å½¢çŠ¶ä» {original_shape} é‡å¡‘ä¸º {features.shape}")
            
            # é‡‡æ ·æ•°æ®ä»¥åŠ é€Ÿt-SNE
            if features.shape[0] > 10000:
                indices = np.random.choice(features.shape[0], 5000, replace=False)
                features_sample = features[indices]
                labels_sample = labels[indices] if len(labels) == features.shape[0] else labels.flatten()[indices]
                logger.info(f"é‡‡æ · {len(indices)} ä¸ªæ ·æœ¬è¿›è¡Œt-SNE")
            else:
                features_sample = features
                labels_sample = labels.flatten() if len(labels.shape) > 1 else labels
            
            # ç¡®ä¿æ ‡ç­¾å’Œç‰¹å¾æ•°é‡åŒ¹é…
            if len(labels_sample) != features_sample.shape[0]:
                logger.warning(f"æ ‡ç­¾æ•°é‡ {len(labels_sample)} ä¸ç‰¹å¾æ•°é‡ {features_sample.shape[0]} ä¸åŒ¹é…")
                min_len = min(len(labels_sample), features_sample.shape[0])
                features_sample = features_sample[:min_len]
                labels_sample = labels_sample[:min_len]
            
            # è¿‡æ»¤æœ‰æ•ˆæ ‡ç­¾
            valid_mask = (labels_sample >= 0) & (labels_sample <= 5)
            features_sample = features_sample[valid_mask]
            labels_sample = labels_sample[valid_mask]
            
            if len(features_sample) < 100:
                logger.warning(f"æœ‰æ•ˆæ ·æœ¬å¤ªå°‘ ({len(features_sample)})ï¼Œè·³è¿‡t-SNE")
                return
            
            # è¿è¡Œt-SNE
            logger.info(f"è¿è¡Œt-SNEï¼Œç‰¹å¾ç»´åº¦: {features_sample.shape}")
            tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(features_sample)//4))
            features_2d = tsne.fit_transform(features_sample)
            
            # å¯è§†åŒ–
            plt.figure(figsize=(12, 10))
            colors = ['white', 'blue', 'cyan', 'green', 'yellow', 'red']
            
            for i, (class_name, color) in enumerate(zip(self.class_names, colors)):
                mask = labels_sample == i
                if np.sum(mask) > 0:
                    plt.scatter(features_2d[mask, 0], features_2d[mask, 1], 
                              c=color, label=f'{class_name} ({np.sum(mask)})', 
                              alpha=0.6, s=2, edgecolors='black', linewidth=0.1)
            
            plt.title(f't-SNE Feature Visualization - Area {area_id}', fontsize=16, fontweight='bold')
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.tight_layout()
            
            save_path = os.path.join(self.args.output_dir, f'tsne_features_area{area_id}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            logger.info(f"ä¿å­˜t-SNEç‰¹å¾å¯è§†åŒ–: {save_path}")
        except Exception as e:
            logger.error(f"t-SNEç‰¹å¾å¯è§†åŒ–å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
    
    def visualize_attention_maps(self, rgb, dsm, area_id):
        """ç”Ÿæˆæ³¨æ„åŠ›çƒ­åŠ›å›¾"""
        try:
            # ä½¿ç”¨æ¨¡å‹ç”Ÿæˆæ³¨æ„åŠ›å›¾
            h, w = rgb.shape[:2]
            
            # ä½¿ç”¨å°å—è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ä»¥é¿å…å†…å­˜é—®é¢˜
            patch_size = 256
            rgb_patch = rgb[:patch_size, :patch_size]
            dsm_patch = dsm[:patch_size, :patch_size]
            
            # ç®€åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨æ¢¯åº¦ä½œä¸ºæ³¨æ„åŠ›
            rgb_tensor = torch.from_numpy(rgb_patch.astype(np.float32) / 255.0).permute(2, 0, 1).unsqueeze(0).to(self.device)
            dsm_tensor = torch.from_numpy(dsm_patch.astype(np.float32)).unsqueeze(0).unsqueeze(0).to(self.device)
            
            rgb_tensor.requires_grad_(True)
            dsm_tensor.requires_grad_(True)
            
            with torch.enable_grad():
                output = self.model({'rgb': rgb_tensor, 'dsm': dsm_tensor})
                if isinstance(output, tuple):
                    output = output[0]
                
                # è®¡ç®—æ¢¯åº¦ä½œä¸ºæ³¨æ„åŠ›
                loss = output.sum()
                loss.backward()
                
                rgb_attention = torch.abs(rgb_tensor.grad).mean(dim=1).squeeze().cpu().numpy()
                dsm_attention = torch.abs(dsm_tensor.grad).squeeze().cpu().numpy()
            
            # å¯è§†åŒ–æ³¨æ„åŠ›å›¾
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            
            # RGBæ³¨æ„åŠ›çƒ­åŠ›å›¾
            im1 = axes[0,0].imshow(rgb_attention, cmap='hot', interpolation='bilinear')
            axes[0,0].set_title('RGB Attention Heatmap')
            axes[0,0].axis('off')
            plt.colorbar(im1, ax=axes[0,0], fraction=0.046, pad=0.04)
            
            # RGBæ³¨æ„åŠ›å åŠ å›¾
            rgb_norm = rgb_patch / 255.0
            overlay_rgb = 0.6 * rgb_norm + 0.4 * plt.cm.hot(rgb_attention)[:,:,:3]
            axes[0,1].imshow(np.clip(overlay_rgb, 0, 1))
            axes[0,1].set_title('RGB + Attention Overlay')
            axes[0,1].axis('off')
            
            # DSMæ³¨æ„åŠ›çƒ­åŠ›å›¾
            im2 = axes[1,0].imshow(dsm_attention, cmap='plasma', interpolation='bilinear')
            axes[1,0].set_title('DSM Attention Heatmap')
            axes[1,0].axis('off')
            plt.colorbar(im2, ax=axes[1,0], fraction=0.046, pad=0.04)
            
            # DSMæ³¨æ„åŠ›å åŠ å›¾
            dsm_norm = (dsm_patch - dsm_patch.min()) / (dsm_patch.max() - dsm_patch.min())
            overlay_dsm = 0.6 * plt.cm.gray(dsm_norm)[:,:,:3] + 0.4 * plt.cm.plasma(dsm_attention)[:,:,:3]
            axes[1,1].imshow(np.clip(overlay_dsm, 0, 1))
            axes[1,1].set_title('DSM + Attention Overlay')
            axes[1,1].axis('off')
            
            plt.tight_layout()
            save_path = os.path.join(self.args.output_dir, f'attention_maps_area{area_id}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            logger.info(f"ä¿å­˜æ³¨æ„åŠ›çƒ­åŠ›å›¾: {save_path}")
        except Exception as e:
            logger.error(f"æ³¨æ„åŠ›çƒ­åŠ›å›¾ç”Ÿæˆå¤±è´¥: {e}")
    
    def visualize_feature_fusion(self, rgb, dsm, prediction, area_id):
        """ç‰¹å¾èåˆå¯è§†åŒ–"""
        try:
            fig, axes = plt.subplots(2, 3, figsize=(18, 12))
            
            # ç¬¬ä¸€è¡Œï¼šè¾“å…¥æ•°æ®
            axes[0,0].imshow(rgb)
            axes[0,0].set_title('RGB Input', fontsize=14, fontweight='bold')
            axes[0,0].axis('off')
            
            axes[0,1].imshow(dsm, cmap='gray')
            axes[0,1].set_title('DSM Input', fontsize=14, fontweight='bold')
            axes[0,1].axis('off')
            
            # èåˆå¯è§†åŒ–ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            fusion_vis = np.stack([rgb[:,:,0]/255.0, dsm/dsm.max(), rgb[:,:,1]/255.0], axis=2)
            axes[0,2].imshow(fusion_vis)
            axes[0,2].set_title('RGB-DSM Fusion', fontsize=14, fontweight='bold')
            axes[0,2].axis('off')
            
            # ç¬¬äºŒè¡Œï¼šé¢„æµ‹ç»“æœ
            pred_colored = convert_to_color(prediction)
            axes[1,0].imshow(pred_colored)
            axes[1,0].set_title('Prediction Result', fontsize=14, fontweight='bold')
            axes[1,0].axis('off')
            
            # ç½®ä¿¡åº¦å›¾ - ä½¿ç”¨é¢„æµ‹ç±»åˆ«çš„åˆ†å¸ƒä½œä¸ºç½®ä¿¡åº¦
            confidence = np.ones_like(prediction, dtype=np.float32) * 0.5  # é»˜è®¤ç½®ä¿¡åº¦
            unique_classes = np.unique(prediction)
            for cls in unique_classes:
                mask = prediction == cls
                confidence[mask] = 0.8 + 0.2 * (cls / 5.0)  # ç®€å•çš„ç½®ä¿¡åº¦æ¨¡æ‹Ÿ
            
            im = axes[1,1].imshow(confidence, cmap='viridis')
            axes[1,1].set_title('Confidence Map', fontsize=14, fontweight='bold')
            axes[1,1].axis('off')
            plt.colorbar(im, ax=axes[1,1])
            
            # è¾¹ç•Œæ£€æµ‹
            from scipy import ndimage
            edges = ndimage.sobel(rgb.mean(axis=2))
            axes[1,2].imshow(edges, cmap='gray')
            axes[1,2].set_title('Edge Detection', fontsize=14, fontweight='bold')
            axes[1,2].axis('off')
            
            plt.tight_layout()
            save_path = os.path.join(self.args.output_dir, f'feature_fusion_area{area_id}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            logger.info(f"ä¿å­˜ç‰¹å¾èåˆå¯è§†åŒ–: {save_path}")
        except Exception as e:
            logger.error(f"ç‰¹å¾èåˆå¯è§†åŒ–å¤±è´¥: {e}")
    
    def _run_parallel_evaluation(self):
        """å¹¶è¡Œè¯„ä¼°æ¨¡å¼ - 4GPUè‡ªåŠ¨å¹¶è¡Œ"""
        import multiprocessing as mp
        import subprocess
        import time
        
        logger.info("ğŸš€ å¯åŠ¨4GPUå¹¶è¡Œè¯„ä¼°...")
        
        # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        processes = []
        area_ids = self.args.area_ids
        gpu_count = min(4, torch.cuda.device_count())
        
        for i, area_id in enumerate(area_ids):
            gpu_id = i % gpu_count
            
            # ä¸ºæ¯ä¸ªGPUåˆ›å»ºç‹¬ç«‹çš„è¾“å‡ºç›®å½•
            gpu_output_dir = os.path.join(self.args.output_dir, f'gpu{gpu_id}_area{area_id}')
            
            # æ„å»ºå‘½ä»¤
            cmd = [
                'python', '-c', f'''
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "{gpu_id}"
import sys
sys.path.append("{os.getcwd()}")

from evaluate_top_tier import TopTierEvaluator
import argparse

# åˆ›å»ºå‚æ•°å¯¹è±¡
class Args:
    def __init__(self):
        self.model_path = "{self.args.model_path}"
        self.data_path = "{self.args.data_path}"
        self.output_dir = "{gpu_output_dir}"
        self.area_ids = [{area_id}]
        self.stride = {self.args.stride if hasattr(self.args, 'stride') else 8}
        self.window_size = {self.args.window_size if hasattr(self.args, 'window_size') else 256}
        self.batch_size = {self.args.batch_size if hasattr(self.args, 'batch_size') else 4}
        self.use_multi_strategy = {getattr(self.args, 'use_multi_strategy', True)}
        self.embed_dim = {getattr(self.args, 'embed_dim', None)}
        self.ablation_stride = {getattr(self.args, 'ablation_stride', 32)}

args = Args()
evaluator = TopTierEvaluator(args)
result = evaluator._run_serial_evaluation()
print(f"GPU {gpu_id} Area {area_id} å®Œæˆ")
'''
            ]
            
            logger.info(f"ğŸ”¥ GPU {gpu_id} å¼€å§‹å¤„ç† Area {area_id}")
            
            # å¯åŠ¨è¿›ç¨‹
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            processes.append((process, area_id, gpu_id, gpu_output_dir))
        
        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
        logger.info("â³ ç­‰å¾…æ‰€æœ‰GPUå®Œæˆè¯„ä¼°...")
        
        completed_results = {}
        for process, area_id, gpu_id, output_dir in processes:
            stdout, stderr = process.communicate()
            
            if process.returncode == 0:
                logger.info(f"âœ… GPU {gpu_id} Area {area_id} è¯„ä¼°æˆåŠŸ")
                completed_results[area_id] = {
                    'gpu_id': gpu_id,
                    'output_dir': output_dir,
                    'success': True
                }
            else:
                logger.error(f"âŒ GPU {gpu_id} Area {area_id} è¯„ä¼°å¤±è´¥")
                logger.error(f"é”™è¯¯: {stderr}")
                completed_results[area_id] = {
                    'gpu_id': gpu_id,
                    'output_dir': output_dir,
                    'success': False,
                    'error': stderr
                }
        
        # åˆå¹¶ç»“æœ
        logger.info("ğŸ”„ åˆå¹¶å¹¶è¡Œè¯„ä¼°ç»“æœ...")
        self._merge_parallel_results(completed_results)
        
        logger.info("âœ… 4GPUå¹¶è¡Œè¯„ä¼°å®Œæˆ!")
        return completed_results, {}
    
    def _run_simple_parallel_evaluation(self):
        """ç®€åŒ–çš„4GPUå¹¶è¡Œè¯„ä¼° - ç›´æ¥ä½¿ç”¨shellå‘½ä»¤"""
        import subprocess
        import time
        
        logger.info("ğŸš€ å¯åŠ¨ç®€åŒ–4GPUå¹¶è¡Œè¯„ä¼°...")
        
        area_ids = self.args.area_ids
        processes = []
        
        # ä¸ºæ¯ä¸ªåŒºåŸŸå¯åŠ¨ç‹¬ç«‹çš„è¯„ä¼°è¿›ç¨‹
        for i, area_id in enumerate(area_ids):
            gpu_id = i % 4
            output_dir = f"{self.args.output_dir}_gpu{gpu_id}_area{area_id}"
            
            # æ„å»ºç®€åŒ–çš„å‘½ä»¤
            cmd = [
                'python', 'evaluate_top_tier.py',
                '--checkpoint', str(self.args.model_path),
                '--data_path', str(self.args.data_path), 
                '--output_dir', output_dir,
                '--area_ids', str(area_id),
                '--stride', str(getattr(self.args, 'stride', 8)),
                '--window_size', str(getattr(self.args, 'window_size', 256)),
                '--batch_size', str(getattr(self.args, 'batch_size', 4)),
                '--disable_multi_strategy'  # å¼ºåˆ¶ç¦ç”¨å¤šç­–ç•¥
            ]
            
            # è®¾ç½®GPUç¯å¢ƒ
            env = os.environ.copy()
            env['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
            
            logger.info(f"ğŸ”¥ GPU {gpu_id} å¼€å§‹å¤„ç† Area {area_id} (ç®€åŒ–æ¨¡å¼)")
            
            # å¯åŠ¨è¿›ç¨‹
            process = subprocess.Popen(
                cmd,
                env=env,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            processes.append((process, area_id, gpu_id, output_dir))
        
        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ - å¸¦å¿ƒè·³ç›‘æ§
        logger.info("â³ ç­‰å¾…æ‰€æœ‰GPUå®Œæˆç®€åŒ–è¯„ä¼°...")
        
        completed_results = {}
        for i, (process, area_id, gpu_id, output_dir) in enumerate(processes):
            try:
                logger.info(f"âŒ› ç­‰å¾…GPU {gpu_id} Area {area_id}å®Œæˆ... ({i+1}/{len(processes)})")
                
                # å¸¦å¿ƒè·³ç›‘æ§çš„ç­‰å¾…ï¼Œæ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                start_wait_time = time.time()
                while process.poll() is None:
                    try:
                        stdout, stderr = process.communicate(timeout=60)  # 1åˆ†é’Ÿå¿ƒè·³æ£€æŸ¥
                        break
                    except subprocess.TimeoutExpired:
                        elapsed_wait = time.time() - start_wait_time
                        logger.info(f"ğŸ’“ GPU {gpu_id} Area {area_id} ä»åœ¨è¿è¡Œ... (å·²è¿è¡Œ {elapsed_wait/60:.1f}åˆ†é’Ÿ)")
                        # ç§»é™¤å¼ºåˆ¶ç»ˆæ­¢ï¼Œè®©è¿›ç¨‹è‡ªç„¶å®Œæˆ
                
                # è·å–æœ€ç»ˆè¾“å‡º
                if process.poll() is not None:
                    stdout, stderr = process.communicate()
                
                if process.returncode == 0:
                    logger.info(f"âœ… GPU {gpu_id} Area {area_id} ç®€åŒ–è¯„ä¼°æˆåŠŸ")
                    completed_results[area_id] = {
                        'gpu_id': gpu_id,
                        'output_dir': output_dir,
                        'success': True
                    }
                else:
                    logger.error(f"âŒ GPU {gpu_id} Area {area_id} ç®€åŒ–è¯„ä¼°å¤±è´¥")
                    logger.error(f"é”™è¯¯: {stderr}")
                    completed_results[area_id] = {
                        'gpu_id': gpu_id,
                        'output_dir': output_dir,
                        'success': False,
                        'error': stderr
                    }
            except Exception as e:
                logger.error(f"ğŸ’¥ GPU {gpu_id} Area {area_id} è¯„ä¼°å¼‚å¸¸: {e}")
                completed_results[area_id] = {
                    'gpu_id': gpu_id,
                    'output_dir': output_dir,
                    'success': False,
                    'error': str(e)
                }
        
        # åˆå¹¶ç»“æœ
        logger.info("ğŸ”„ åˆå¹¶ç®€åŒ–å¹¶è¡Œè¯„ä¼°ç»“æœ...")
        self._merge_parallel_results(completed_results)
        
        logger.info("âœ… ç®€åŒ–4GPUå¹¶è¡Œè¯„ä¼°å®Œæˆ!")
        return completed_results, {}
    
    def _merge_parallel_results(self, completed_results):
        """åˆå¹¶å¹¶è¡Œè¯„ä¼°çš„ç»“æœ"""
        try:
            import shutil
            
            # åˆ›å»ºåˆå¹¶ç›®å½•
            merged_dir = os.path.join(self.args.output_dir, 'merged_results')
            os.makedirs(merged_dir, exist_ok=True)
            
            for area_id, result_info in completed_results.items():
                if result_info['success']:
                    source_dir = result_info['output_dir']
                    
                    if os.path.exists(source_dir):
                        # å¤åˆ¶æ–‡ä»¶åˆ°åˆå¹¶ç›®å½•
                        for file in os.listdir(source_dir):
                            if file.endswith(('.png', '.txt', '.json')):
                                src_file = os.path.join(source_dir, file)
                                dst_file = os.path.join(merged_dir, f'area{area_id}_{file}')
                                shutil.copy2(src_file, dst_file)
            
            logger.info(f"ğŸ“ ç»“æœå·²åˆå¹¶åˆ°: {merged_dir}")
            
        except Exception as e:
            logger.error(f"âŒ ç»“æœåˆå¹¶å¤±è´¥: {e}")
    
    def save_evaluation_report(self, all_results, overall_metrics):
        """ä¿å­˜è¯„ä¼°æŠ¥å‘Š"""
        report_path = os.path.join(self.args.output_dir, 'comprehensive_evaluation_report.txt')
        
        with open(report_path, 'w') as f:
            f.write("é¡¶åˆŠçº§ç»¼åˆè¯„ä¼°æŠ¥å‘Š\n")
            f.write("=" * 80 + "\n\n")
            
            # æ€»ä½“æŒ‡æ ‡
            avg_oa = np.mean(overall_metrics['oa'])
            avg_aa = np.mean(overall_metrics['aa'])
            avg_miou = np.mean(overall_metrics['miou'])
            
            f.write("æ€»ä½“æŒ‡æ ‡:\n")
            f.write(f"  å¹³å‡OA: {avg_oa:.4f}\n")
            f.write(f"  å¹³å‡AA: {avg_aa:.4f}\n")
            f.write(f"  å¹³å‡mIoU (å‰5ç±»): {avg_miou:.4f}\n\n")
            
            # å„ç±»åˆ«å¹³å‡æŒ‡æ ‡
            f.write("å„ç±»åˆ«å¹³å‡æŒ‡æ ‡:\n")
            for i, name in enumerate(self.class_names):
                try:
                    # ä»all_resultsä¸­æå–å„ç±»åˆ«æŒ‡æ ‡
                    precisions = [result['metrics']['precision'][i] for result in all_results.values()]
                    recalls = [result['metrics']['recall'][i] for result in all_results.values()]
                    f1s = [result['metrics']['f1'][i] for result in all_results.values()]
                    ious = [result['metrics']['per_class_iou'][i] for result in all_results.values()]
                    
                    avg_precision = np.mean(precisions)
                    avg_recall = np.mean(recalls)
                    avg_f1 = np.mean(f1s)
                    avg_iou = np.mean(ious)
                    
                    f.write(f"  {name}:\n")
                    f.write(f"    Precision: {avg_precision:.4f}\n")
                    f.write(f"    Recall: {avg_recall:.4f}\n")
                    f.write(f"    F1: {avg_f1:.4f}\n")
                    f.write(f"    IoU: {avg_iou:.4f}\n\n")
                except Exception as e:
                    f.write(f"  {name}: è®¡ç®—å¤±è´¥ ({e})\n\n")
            
            # å„åŒºåŸŸç»“æœ
            f.write("å„æµ‹è¯•åŒºåŸŸç»“æœ:\n")
            for area_id, result in all_results.items():
                f.write(f"  Area {area_id}:\n")
                f.write(f"    OA: {result['oa']:.4f}\n")
                f.write(f"    AA: {result['aa']:.4f}\n")
    
    def _generate_top_tier_tsne(self, intermediate_features, labels, area_id):
        """ç”Ÿæˆé¡¶åˆŠçº§t-SNEå¯è§†åŒ–"""
        if self.top_tier_tsne_viz is not None:
            try:
                logger.info(f"ç”Ÿæˆé¡¶åˆŠçº§t-SNEå¯è§†åŒ– - Area {area_id}")
                
                # åˆ›å»ºå‘è¡¨çº§t-SNE
                self.top_tier_tsne_viz.create_publication_tsne(
                    intermediate_features, labels, area_id, "Final"
                )
                
                # åˆ›å»ºå¤šé˜¶æ®µå¯¹æ¯”
                if isinstance(intermediate_features, dict):
                    self.top_tier_tsne_viz.create_multi_stage_comparison(
                        intermediate_features, labels, area_id
                    )
                
                logger.info("âœ… é¡¶åˆŠçº§t-SNEå¯è§†åŒ–å®Œæˆ")
                
            except Exception as e:
                logger.error(f"âŒ é¡¶åˆŠçº§t-SNEå¯è§†åŒ–å¤±è´¥: {e}")
        else:
            logger.warning("âš ï¸ é¡¶åˆŠçº§t-SNEå¯è§†åŒ–å™¨æœªåˆå§‹åŒ–")
    
    def _generate_top_tier_heatmap(self, rgb, dsm, intermediate_features, area_id):
        """ç”Ÿæˆé¡¶åˆŠçº§çƒ­åŠ›å›¾å¯è§†åŒ–"""
        if self.top_tier_heatmap_viz is not None:
            try:
                logger.info(f"ç”Ÿæˆé¡¶åˆŠçº§çƒ­åŠ›å›¾å¯è§†åŒ– - Area {area_id}")
                
                # åˆ›å»ºå‘è¡¨çº§çƒ­åŠ›å›¾
                self.top_tier_heatmap_viz.create_publication_heatmap(
                    rgb, dsm, intermediate_features, area_id
                )
                
                logger.info("âœ… é¡¶åˆŠçº§çƒ­åŠ›å›¾å¯è§†åŒ–å®Œæˆ")
                
            except Exception as e:
                logger.error(f"âŒ é¡¶åˆŠçº§çƒ­åŠ›å›¾å¯è§†åŒ–å¤±è´¥: {e}")
        else:
            logger.warning("âš ï¸ é¡¶åˆŠçº§çƒ­åŠ›å›¾å¯è§†åŒ–å™¨æœªåˆå§‹åŒ–")


def main():
    parser = argparse.ArgumentParser(description='é¡¶åˆŠçº§è¯„ä¼°ä¸å¯è§†åŒ–ç³»ç»Ÿ')
    parser.add_argument('--model_path', '--checkpoint', type=str, required=True, help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--dataset', type=str, default='vaihingen', 
                        choices=['vaihingen', 'augsburg', 'muufl', 'trento'],
                        help='æ•°æ®é›†åç§°')
    parser.add_argument('--data_path', type=str, default='./data', help='æ•°æ®è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='top_tier_results', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--area_ids', type=int, nargs='+', default=[5, 15, 21, 30], help='æµ‹è¯•åŒºåŸŸID')
    parser.add_argument('--ablation_stride', type=int, default=32, help='æ¶ˆèå®éªŒä¸“ç”¨æ»‘çª—æ­¥é•¿ï¼ˆä»…ç”¨äºæ¶ˆèè¯„ä¼°ï¼‰')
    parser.add_argument('--stride', type=int, default=4, help='è¯„ä¼°æ»‘çª—æ­¥é•¿')
    parser.add_argument('--embed_dim', type=int, default=None, help='æ¨¡å‹embed_dimè¦†ç›–ï¼ˆä¸è®­ç»ƒä¸€è‡´æ—¶ç•™ç©ºï¼‰')
    parser.add_argument('--batch_size', type=int, default=8, help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--window_size', type=int, default=256, help='æ»‘åŠ¨çª—å£å¤§å°')
    parser.add_argument('--use_multi_strategy', action='store_true', default=True, help='å¯ç”¨å¤šç­–ç•¥é›†æˆï¼ˆé»˜è®¤å¼€å¯ï¼‰')
    parser.add_argument('--disable_multi_strategy', action='store_true', help='ç¦ç”¨å¤šç­–ç•¥é›†æˆ')
    
    args = parser.parse_args()
    
    # å¤„ç†å¤šç­–ç•¥é›†æˆå‚æ•°
    if args.disable_multi_strategy:
        args.use_multi_strategy = False
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    evaluator = TopTierEvaluator(args)
    evaluator.run_comprehensive_evaluation()
    
    logger.info("è¯„ä¼°å®Œæˆï¼æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆ")


if __name__ == '__main__':
    main()

